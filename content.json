[{"title":"Mysql 操作笔记","date":"2018-02-02T09:03:00.000Z","path":"2018/02/02/Mysql_操作笔记/","text":"1.登录1cd usr/local/mysql/bin ---&gt;./myql -uroot 2.创建数据库1CREATE DATABASE IF NOT EXISTS jxytest DEFAULT CHARSET utf8 COLLATE utf8_general_ci; 3.为用户授权操作数据库1grant all on jxytest.* to &apos;yxy_jx&apos;@&apos;%&apos; identified by &apos;lzyljd_yxyjx_2017&apos; with grant option; 4.刷出权限1flush privileges; 查看Mysql最大文件导入大小1show VARIABLES like &apos;%max_allowed_packet%&apos;; 设置最大文件导入大小：1set global max_allowed_packet = 9*1024*1024*100; // 900M 5.慢查询1show status 显示系统状态参数 1.查询慢查询是否开启：123show global variables like &apos;%slow_query%&apos;;slow_query_log 为OFF 表示没有开启，mysql默认是没有开启慢查询日志记录功能的set slow_query_log=1 开启慢查询日志记录 2.查看慢查询时间1show variables like &apos;long_query_time&apos;; 默认为10秒钟，意识是大于10s才算慢查询 3.修改慢查询记录的时间1set long_query_time=1; 设置时间为1s 4.记录慢查询日志的次数1show status like &apos;slow_queries&apos;;","tags":[{"name":"MySQL","slug":"MySQL","permalink":"https://yongliangzhang.github.io/blogs/tags/MySQL/"}]},{"title":"Hadoop MapReduce优化和资源调度器","date":"2018-02-01T06:06:18.374Z","path":"2018/02/01/Hadoop_MapReduce优化和资源调度器/","text":"Hadoop Shuffle过程 1.Hadoop MapReduce Shuffle过程 Hadoop Shuffle过程 Map Shuffle过程图2 2.Shuffle过程要点记录 每个Map Task把输出结果写到内存中的环形缓冲区。 当内存环形缓冲区写入的数据量达到一定阈值时，后台线程会把 数据溢写到磁盘。 根据Partitioner，把数据写入到不同的partition 对于每个partition的数据进行排序 随着Map Task的不断运行，磁盘上的溢出文件越来越多 将这些溢出文件合并 对于一个partition下的不同分片，使用归并排序，同一分区内数据有序 Reduce Task通过网络远程拷贝MapTask的结果文件中的属于它的分区数据 合并所有已拷贝过来的数据文件 采用归并排序算法，对文件数据内容整理排序，将相同key的数据分 为一组，不同key之间有序 最终生成一个key对应一组值的数据集，一个key对应的一组数据会调用一次reduce方法3. Combinery优化总结 Combiner优化 Combiner调用的地方 MapTask的环形缓冲区向磁盘溢写文件之前调用Combiner Map阶段在合并本地多个文件写入一个大文件之前调用Combiner 使用Combiner的好处 减少Map Task输出数据量，由于临时结果写入到本地磁盘，所以能 够减少磁盘IO 减少Reduce-Map网络传输数据量，由于reduce需要远程通过网络从 Map拷贝数据，提高拷贝速度 应用场景 针对结果可以叠加的场景 SUM(YES) Average（NO） 设置方法（local reducer） job.setCombinerClass(WordCountReducer.class)4.YARN 资源调度器1. YARN-FIFO Scheduler将所有应用程序放入到一个队列中 先进入队里排在前面的程序先获得资源局限性 资源利用率低，无法交叉运行作业 不够灵活，比如紧急的作业无法插队，耗时长作业拖慢耗时短作业2. YARN-多队列分开调度器所有资源按照比例划分到不同的队列 每个队列可以实现单独的调度策略 优点 按照不同的资源使用情况将资源划分到不同队列 能够让更多的应用程序获得资源 使用灵活，资源利用率高 调度器 CapacityScheduler调度器 FairScheduler调度器 CapacityScheduler 由Yahoo开源，共享集群调度器 以队列方式组织作业 每个队列内部采用FIFO调度策略 每个队列分配一定比例资源 可限制每个用户使用资源量 CapacityScheduler.png CapacityScheduler 配置方法 在yarn-site.xml 设置使用CapacityScheduler调度器 1234&lt;property&gt; &lt;name&gt;yarn.resourcemanager.scheduler.class&lt;/name&gt; &lt;value&gt;org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler&lt;/value&gt;&lt;/property&gt; 在Hadoop配置文件目录下/usr/local/hadoop/etc/hadoop创建capacity-scheduler.xml,添加信息如下： 123456789101112131415161718&lt;configuration&gt; &lt;property&gt; &lt;name&gt;yarn.scheduler.capacity.root.queues&lt;/name&gt; &lt;value&gt;default,data-bi&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;yarn.scheduler.capacity.root.default.capacity&lt;/name&gt; &lt;value&gt;60&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;yarn.scheduler.capacity.root.default.maximum-capacity&lt;/name&gt; &lt;value&gt;80&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;yarn.scheduler.capacity.root.bi.capacity&lt;/name&gt; &lt;value&gt;40&lt;/vaule&gt; &lt;/property&gt;&lt;/configuration&gt; 配置说明 capacity-scheduler.xml参数说明 capacity：队列占用的集群资源容量百分比，所有队列的容量 之和应小于100 maximum-capacity：由于存在资源共享，因此一个队列使用 的资源量可能超过其容量，而最多使用资源量可通过该参数 限制 配置完成无需重启YARN，使用管理命令刷新调度配置 bin/yarn rmadmin -refreshQueues FairScheduler 公平调度器的目的: 允许多用户共享集群资源。 允许短时的临时作业与长时作业共享集群资源 根据比例来管理集群资源，确保集群资源的有效利用’ FairScheduler配置方法在Hadoop配置目录下/usr/local/hadoop/etc/hadoop yarn-site.xml 增加如下信息：12345678910111213141516&lt;property&gt; &lt;name&gt;yarn.resourcemanager.scheduler.class&lt;/name&gt; &lt;value&gt;org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;yarn.scheduler.fair.user-as-default-queue&lt;/name&gt; &lt;value&gt;true&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;yarn.scheduler.fair.allocation.file&lt;/name&gt; &lt;value&gt;/usr/local/hadoop/etc/hadoop/fair-scheduler.xml&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;yarn.scheduler.fair.preemption&lt;/name&gt; &lt;value&gt;true&lt;/value&gt; &lt;/property&gt; 新建一个公平调度配置文件fair-scheduler.xml ，信息如下： 12345678&lt;allocations&gt; &lt;queue name=&quot;data_bi&quot;&gt; &lt;minResources&gt;8000 mb,4 vcores&lt;/minResources&gt; &lt;maxResources&gt;10000 mb, 6 vcores&lt;/maxResources&gt; &lt;maxRunningApps&gt;2&lt;/maxRunningApps&gt; &lt;weight&gt;1.0&lt;/weight&gt; &lt;/queue&gt;&lt;/allocations&gt; 上述配置以 data_bi 用户名作为公平调度的队列名称。 yarn-site.xml参数说明 yarn.resourcemanager.scheduler.class配置yarn使用的调度器类型 yarn.scheduler.fair.allocation.file配置公平调度器自定义配置文件路径，该文件每隔10秒就会被加载一次，这样就可以在集群运行过程中改变队列的配置 yarn.scheduler.fair.user-as-default-queue当应用程序未指定队列名时，是否指定用户名作为应用程序所在的队列名。如果设置为false或者未设置，所有 未知队列的应用程序将被提交到default队列中，默认值为true yarn.scheduler.fair.preemption如果一个队列占用的资源量少于最小资源量限制，是否启用资源抢占，默认false。抢占机制可以使其他队列的作业容器终止，从而使占用的资源让出，将资源分配给占用资源量少于最小资源量限制的队列 fair-scheduler.xml参数说明 queue name：配置队列名 minResources ：分配给该队列的最小资源量，设置格式为“X mb, Y vcores”，当调度策略属性schedulingPolicy的属性值是fair时，其cores值会被忽略，仅按照申请的内存大小来调度。 maxResources：分配给该队列的最大资源量。设置格式为“X mb, Y vcores”，当调度策略属性schedulingPolicy的属性值是fair时，其cores值会被忽略，仅按照申请的内存大小来调度。 maxRunningApps：最多同时运行的应用程序数目。通过限制该数目，可防止超量MapTask同时运行时产生的中间输出结果撑爆磁盘。 weight：标记了资源池的权重，当资源池中有任务等待，并且集群中有空闲资源时候，每个资源池可以根据权重获得不同比例的集群空闲资源，默认值是1","tags":[]},{"title":"CentOS磁盘空间爆满的解决办法","date":"2018-02-01T06:04:28.743Z","path":"2018/02/01/CentOS磁盘空间爆满的解决办法/","text":"1.查看磁盘具体占用情况12345678910[root@localhost gsidc]# df -hTFilesystem Type Size Used Avail Use% Mounted on/dev/sda3 xfs 92G 21G 72G 23% /devtmpfs devtmpfs 7.8G 0 7.8G 0% /devtmpfs tmpfs 7.8G 0 7.8G 0% /dev/shmtmpfs tmpfs 7.8G 129M 7.7G 2% /runtmpfs tmpfs 7.8G 0 7.8G 0% /sys/fs/cgroup/dev/sda1 xfs 197M 192M 5.0M 98% /boottmpfs tmpfs 1.6G 12K 1.6G 1% /run/user/42tmpfs tmpfs 1.6G 0 1.6G 0% /run/user/1000 2.删除具体位置磁盘占用无用文件3. 查看磁盘删除情况1[root@localhost gsidc]# lsof |grep delete 4. 彻底释放磁盘空间1234567891011121314mysqld_sa 11317 root cwd DIR 8,6 0 102107 /usr/local/mysql (deleted)mysqld_sa 11317 root 255r REG 8,6 13620 102182 /usr/local/mysql/bin/mysqld_safe (deleted)mysqld 11353 mysql txt REG 8,6 29382763 102138 /usr/local/mysql/bin/mysqld (deleted)mysqld 11353 mysql 5u REG 8,9 0 58761 /tmp/ibpfbHsa (deleted)mysqld 11353 mysql 6u REG 8,9 0 58771 /tmp/ibqoMnag (deleted)mysqld 11353 mysql 7u REG 8,9 0 58772 /tmp/ibN4C4Rl (deleted)mysqld 11353 mysql 8u REG 8,9 0 58781 /tmp/ibkWP8zr (deleted)mysqld 11353 mysql 12u REG 8,9 0 58782 /tmp/ibnqrZsx (deleted)java 16961 root 1w REG 8,3 5822263296 457562 /opt/tomcat/logs/catalina.out (deleted)java 16961 root 2w REG 8,3 5822263296 457562 /opt/tomcat/logs/catalina.out (deleted)java 16961 root 12w REG 8,3 5469261824 197191 /opt/tomcat/logs/catalina.2013-01-02.log (deleted)java 16961 root 13w REG 8,3 2166784 197192 /opt/tomcat/logs/localhost.2013-01-02.log (deleted)java 16961 root 14w REG 8,3 0 391681 /opt/tomcat/logs/manager.2013-01-02.log (deleted)java 16961 root 15w REG 8,3 0 391682 /opt/tomcat/logs/host-manager.2013-01-02.log (deleted) 关闭删除文件进程1[root@localhost /]# kill -9 16961 磁盘容量恢复","tags":[]},{"title":"Keepalived+Nginx+Tomcat 实现高可用Web集群","date":"2018-02-01T06:03:33.047Z","path":"2018/02/01/Keepalived+Nginx+Tomcat_实现高可用Web集群/","text":"集群规划图片 一、Nginx的安装过程1.下载Nginx安装包，安装依赖环境包(1)安装 C++编译环境1yum -y install gcc #C++ (2)安装pcre1yum -y install pcre-devel (3)安装zlib1yum -y install zlib-devel (4)安装Nginx定位到nginx 解压文件位置，执行编译安装命令123[root@localhost nginx-1.12.2]# pwd/usr/local/nginx/nginx-1.12.2[root@localhost nginx-1.12.2]# ./configure &amp;&amp; make &amp;&amp; make install (5)启动Nginx安装完成后先寻找那安装完成的目录位置123[root@localhost nginx-1.12.2]# whereis nginxnginx: /usr/local/nginx[root@localhost nginx-1.12.2]# 进入Nginx子目录sbin启动Nginxnginx]# cd sbin/12345[root@localhost sbin]# lsnginx[root@localhost sbin]# ./nginx &amp;[1] 5768[root@localhost sbin]# 查看Nginx是否启动 Niginx启动成功截图 或通过进程查看Nginx启动情况123456[root@localhost sbin]# ps -aux|grep nginxroot 5769 0.0 0.0 20484 608 ? Ss 14:03 0:00 nginx: master process ./nginxnobody 5770 0.0 0.0 23012 1620 ? S 14:03 0:00 nginx: worker processroot 5796 0.0 0.0 112668 972 pts/0 R+ 14:07 0:00 grep --color=auto nginx[1]+ 完成 ./nginx[root@localhost sbin]# 到此Nginx安装完成并启动成功。 (6)Nginx快捷启动和开机启动配置编辑Nginx快捷启动脚本【注意Nginx安装路径，需要根据自己的NGINX路径进行改动】1[root@localhost init.d]# vim /etc/rc.d/init.d/nginx 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126#!/bin/sh## nginx - this script starts and stops the nginx daemon## chkconfig: - 85 15# description: Nginx is an HTTP(S) server, HTTP(S) reverse \\# proxy and IMAP/POP3 proxy server# processname: nginx# config: /etc/nginx/nginx.conf# config: /usr/local/nginx/conf/nginx.conf# pidfile: /usr/local/nginx/logs/nginx.pid # Source function library.. /etc/rc.d/init.d/functions # Source networking configuration.. /etc/sysconfig/network # Check that networking is up.[ &quot;$NETWORKING&quot; = &quot;no&quot; ] &amp;&amp; exit 0nginx=&quot;/usr/local/nginx/sbin/nginx&quot;prog=$(basename $nginx)NGINX_CONF_FILE=&quot;/usr/local/nginx/conf/nginx.conf&quot;[ -f /etc/sysconfig/nginx ] &amp;&amp; . /etc/sysconfig/nginxlockfile=/var/lock/subsys/nginx make_dirs() &#123; # make required directories user=`$nginx -V 2&gt;&amp;1 | grep &quot;configure arguments:&quot; | sed &apos;s/[^*]*--user=\\([^ ]*\\).*/\\1/g&apos; -` if [ -z &quot;`grep $user /etc/passwd`&quot; ]; then useradd -M -s /bin/nologin $user fi options=`$nginx -V 2&gt;&amp;1 | grep &apos;configure arguments:&apos;` for opt in $options; do if [ `echo $opt | grep &apos;.*-temp-path&apos;` ]; then value=`echo $opt | cut -d &quot;=&quot; -f 2` if [ ! -d &quot;$value&quot; ]; then # echo &quot;creating&quot; $value mkdir -p $value &amp;&amp; chown -R $user $value fi fi done&#125; start() &#123; [ -x $nginx ] || exit 5 [ -f $NGINX_CONF_FILE ] || exit 6 make_dirs echo -n $&quot;Starting $prog: &quot; daemon $nginx -c $NGINX_CONF_FILE retval=$? echo [ $retval -eq 0 ] &amp;&amp; touch $lockfile return $retval&#125; stop() &#123; echo -n $&quot;Stopping $prog: &quot; killproc $prog -QUIT retval=$? echo [ $retval -eq 0 ] &amp;&amp; rm -f $lockfile return $retval&#125; restart() &#123; #configtest || return $? stop sleep 1 start&#125; reload() &#123; #configtest || return $? echo -n $&quot;Reloading $prog: &quot; killproc $nginx -HUP RETVAL=$? echo&#125; force_reload() &#123; restart&#125; configtest() &#123; $nginx -t -c $NGINX_CONF_FILE&#125; rh_status() &#123; status $prog&#125; rh_status_q() &#123; rh_status &gt;/dev/null 2&gt;&amp;1&#125; case &quot;$1&quot; instart)rh_status_q &amp;&amp; exit 0$1;;stop) rh_status_q || exit 0$1;;restart|configtest)$1;;reload)rh_status_q || exit 7$1;;force-reload)force_reload;;status)rh_status;;condrestart|try-restart)rh_status_q || exit 0;;*)echo $&quot;Usage: $0 &#123;start|stop|status|restart|condrestart|try-restart|reload|force-reload|configtest&#125;&quot;exit 2esac 为启动脚本授权 并加入开机启动12[root@localhost init.d]# chmod -R 777 /etc/rc.d/init.d/nginx [root@localhost init.d]# chkconfig nginx 启动Nginx1[root@localhost init.d]# ./nginx start 将Nginx加入系统环境变量1[root@localhost init.d]# echo &apos;export PATH=$PATH:/usr/local/nginx/sbin&apos;&gt;&gt;/etc/profile &amp;&amp; source /etc/profile Nginx命令 [ service nginx (start|stop|restart) ]12[root@localhost init.d]# service nginx startStarting nginx (via systemctl): [ 确定 ] Tips:快捷命令1service nginx (start|stop|restart) 二、KeepAlived安装和配置1.安装Keepalived依赖环境12345yum install -y popt-devel yum install -y ipvsadmyum install -y libnl*yum install -y libnf*yum install -y openssl-devel 2.编译Keepalived并安装12[root@localhost keepalived-1.3.9]# ./configure[root@localhost keepalived-1.3.9]# make &amp;&amp; make install 3.将Keepalive 安装成系统服务12[root@localhost etc]# mkdir /etc/keepalived[root@localhost etc]# cp /usr/local/keepalived/etc/keepalived/keepalived.conf /etc/keepalived/ 手动复制默认的配置文件到默认路径123[root@localhost etc]# mkdir /etc/keepalived[root@localhost etc]# cp /usr/local/keepalived/etc/sysconfig/keepalived /etc/sysconfig/[root@localhost etc]# cp /usr/local/keepalived/etc/keepalived/keepalived.conf /etc/keepalived/ 为keepalived 创建软链接1[root@localhost sysconfig]# ln -s /usr/local/keepalived/sbin/keepalived /usr/sbin/ 设置Keepalived开机自启动123[root@localhost sysconfig]# chkconfig keepalived on注意：正在将请求转发到“systemctl enable keepalived.service”。Created symlink from /etc/systemd/system/multi-user.target.wants/keepalived.service to /usr/lib/systemd/system/keepalived.service 启动Keepalived服务1[root@localhost keepalived]# keepalived -D -f /etc/keepalived/keepalived.conf 关闭Keepalived服务1[root@localhost keepalived]# killall keepalived 三、集群规划和搭建 集群规划图片 环境准备：CentOS 7.2 Keepalived &nbsp; Version 1.4.0 - December 29, 2017 Nginx &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; Version: nginx/1.12.2 Tomcat &nbsp; &nbsp; &nbsp; &nbsp; Version:8集群规划清单虚拟机 | IP |说明—|—|——-Keepalived+Nginx1[Master] | 192.168.43.101 | Nginx Server 01Keeepalived+Nginx[Backup] | 192.168.43.102 | Nginx Server 02Tomcat01|192.168.43.103|Tomcat Web Server01Tomcat02|192.168.43.104|Tomcat Web Server02VIP|192.168.43.150|虚拟漂移IP 1.更改Tomcat默认欢迎页面，用于标识切换Web 更改TomcatServer01 节点ROOT/index.jsp 信息，加入TomcatIP地址，并加入Nginx值，即修改节点192.168.43.103信息如下：123&lt;div id=&quot;asf-box&quot;&gt; &lt;h1&gt;$&#123;pageContext.servletContext.serverInfo&#125;(192.168.224.103)&lt;%=request.getHeader(&quot;X-NGINX&quot;)%&gt;&lt;/h1&gt;&lt;/div&gt; 更改TomcatServer02 节点ROOT/index.jsp信息，加入TomcatIP地址，并加入Nginx值，即修改节点192.168.43.104信息如下：123&lt;div id=&quot;asf-box&quot;&gt; &lt;h1&gt;$&#123;pageContext.servletContext.serverInfo&#125;(192.168.224.104)&lt;%=request.getHeader(&quot;X-NGINX&quot;)%&gt;&lt;/h1&gt;&lt;/div&gt; 2.启动Tomcat服务，查看Tomcat服务IP信息，此时Nginx未启动，因此request-header没有Nginx信息。 Tomcat启动信息 3.配置Nginx代理信息1.配置Master节点[192.168.43.101]代理信息 1234567891011 upstream tomcat &#123; server 192.168.43.103:8080 weight=1; server 192.168.43.104:8080 weight=1;&#125;server&#123; location / &#123; proxy_pass http://tomcat; proxy_set_header X-NGINX &quot;NGINX-1&quot;; &#125; #......其他省略&#125; 2.配置Backup节点[192.168.43.102]代理信息1234567891011upstream tomcat &#123; server 192.168.43.103:8080 weight=1; server 192.168.43.104:8080 weight=1;&#125;server&#123; location / &#123; proxy_pass http://tomcat; proxy_set_header X-NGINX &quot;NGINX-2&quot;; &#125; #......其他省略&#125; 3.启动Master 节点Nginx服务12[root@localhost init.d]# service nginx startStarting nginx (via systemctl): [ 确定 ] 此时访问 192.168.43.101 可以看到103和104节点Tcomat交替显示，说明Nginx服务已经将请求负载到了2台tomcat上。 Nginx 负载效果 4.同理配置Backup[192.168.43.102] Nginx信息，启动Nginx后，访问192.168.43.102后可以看到Backup节点已起到负载的效果。 Backup负载效果 4.配置Keepalived 脚本信息1.在Master节点和Slave节点 /etc/keepalived目录下添加check_nginx.sh 文件，用于检测Nginx的存货状况，添加keepalived.conf文件 check_nginx.sh文件信息如下： 123456789101112131415#!/bin/bash#时间变量，用于记录日志d=`date --date today +%Y%m%d_%H:%M:%S`#计算nginx进程数量n=`ps -C nginx --no-heading|wc -l`#如果进程为0，则启动nginx，并且再次检测nginx进程数量，#如果还为0，说明nginx无法启动，此时需要关闭keepalivedif [ $n -eq &quot;0&quot; ]; then /etc/rc.d/init.d/nginx start n2=`ps -C nginx --no-heading|wc -l` if [ $n2 -eq &quot;0&quot; ]; then echo &quot;$d nginx down,keepalived will stop&quot; &gt;&gt; /var/log/check_ng.log systemctl stop keepalived fifi 添加完成后，为check_nginx.sh 文件授权，便于脚本获得执行权限。 1[root@localhost keepalived]# chmod -R 777 /etc/keepalived/check_nginx.sh 2.在Master 节点 /etc/keepalived目录下，添加keepalived.conf 文件，具体信息如下：123456789101112131415161718192021222324252627282930vrrp_script chk_nginx &#123; script &quot;/etc/keepalived/check_nginx.sh&quot; //检测nginx进程的脚本 interval 2 weight -20 &#125; global_defs &#123; notification_email &#123; //可以添加邮件提醒 &#125; &#125; vrrp_instance VI_1 &#123; state MASTER #标示状态为MASTER 备份机为BACKUP interface ens33 #设置实例绑定的网卡(ip addr查看，需要根据个人网卡绑定) virtual_router_id 51 #同一实例下virtual_router_id必须相同 mcast_src_ip 192.168.43.101 priority 250 #MASTER权重要高于BACKUP 比如BACKUP为240 advert_int 1 #MASTER与BACKUP负载均衡器之间同步检查的时间间隔，单位是秒 nopreempt #非抢占模式 authentication &#123; #设置认证 auth_type PASS #主从服务器验证方式 auth_pass 123456 &#125; track_script &#123; check_nginx &#125; virtual_ipaddress &#123; #设置vip 192.168.43.150 #可以多个虚拟IP，换行即可 &#125; &#125; 3.在Backup节点 etc/keepalived目录下添加 keepalived.conf 配置文件信息如下： 123456789101112131415161718192021222324252627282930vrrp_script chk_nginx &#123; script &quot;/etc/keepalived/check_nginx.sh&quot; //检测nginx进程的脚本 interval 2 weight -20 &#125; global_defs &#123; notification_email &#123; //可以添加邮件提醒 &#125; &#125; vrrp_instance VI_1 &#123; state BACKUP #标示状态为MASTER 备份机为BACKUP interface ens33 #设置实例绑定的网卡(ip addr查看) virtual_router_id 51 #同一实例下virtual_router_id必须相同 mcast_src_ip 192.168.43.102 priority 240 #MASTER权重要高于BACKUP 比如BACKUP为240 advert_int 1 #MASTER与BACKUP负载均衡器之间同步检查的时间间隔，单位是秒 nopreempt #非抢占模式 authentication &#123; #设置认证 auth_type PASS #主从服务器验证方式 auth_pass 123456 &#125; track_script &#123; check_nginx &#125; virtual_ipaddress &#123; #设置vip 192.168.43.150 #可以多个虚拟IP，换行即可 &#125; &#125; Tips:关于配置信息的几点说明 state - 主服务器需配成MASTER，从服务器需配成BACKUP interface - 这个是网卡名，我使用的是VM12.0的版本，所以这里网卡名为ens33 mcast_src_ip - 配置各自的实际IP地址 priority - 主服务器的优先级必须比从服务器的高，这里主服务器配置成250，从服务器配置成240 virtual_ipaddress - 配置虚拟IP（192.168.43.150） authentication - auth_pass主从服务器必须一致，keepalived靠这个来通信 virtual_router_id - 主从服务器必须保持一致5.集群高可用(HA)验证 Step1 启动Master机器的Keepalived和 Nginx服务 12[root@localhost keepalived]# keepalived -D -f /etc/keepalived/keepalived.conf[root@localhost keepalived]# service nginx start 查看服务启动进程1234[root@localhost keepalived]# ps -aux|grep nginxroot 6390 0.0 0.0 20484 612 ? Ss 19:13 0:00 nginx: master process /usr/local/nginx/sbin/nginx -c /usr/local/nginx/conf/nginx.confnobody 6392 0.0 0.0 23008 1628 ? S 19:13 0:00 nginx: worker processroot 6978 0.0 0.0 112672 968 pts/0 S+ 20:08 0:00 grep --color=auto nginx 查看Keepalived启动进程 12345[root@localhost keepalived]# ps -aux|grep keepalivedroot 6402 0.0 0.0 45920 1016 ? Ss 19:13 0:00 keepalived -D -f /etc/keepalived/keepalived.confroot 6403 0.0 0.0 48044 1468 ? S 19:13 0:00 keepalived -D -f /etc/keepalived/keepalived.confroot 6404 0.0 0.0 50128 1780 ? S 19:13 0:00 keepalived -D -f /etc/keepalived/keepalived.confroot 7004 0.0 0.0 112672 976 pts/0 S+ 20:10 0:00 grep --color=auto keepalived 使用 ip add 查看虚拟IP绑定情况，如出现192.168.43.150 节点信息则绑定到Master节点 12345678910111213141516171819202122232425[root@localhost keepalived]# ip add1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 65536 qdisc noqueue state UNKNOWN qlen 1 link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00 inet 127.0.0.1/8 scope host lo valid_lft forever preferred_lft forever inet6 ::1/128 scope host valid_lft forever preferred_lft forever2: ens33: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc pfifo_fast state UP qlen 1000 link/ether 00:0c:29:91:bf:59 brd ff:ff:ff:ff:ff:ff inet 192.168.43.101/24 brd 192.168.43.255 scope global ens33 valid_lft forever preferred_lft forever inet 192.168.43.150/32 scope global ens33 valid_lft forever preferred_lft forever inet6 fe80::9abb:4544:f6db:8255/64 scope link valid_lft forever preferred_lft forever inet6 fe80::b0b3:d0ca:7382:2779/64 scope link tentative dadfailed valid_lft forever preferred_lft forever inet6 fe80::314f:5fe7:4e4b:64ed/64 scope link tentative dadfailed valid_lft forever preferred_lft forever3: virbr0: &lt;NO-CARRIER,BROADCAST,MULTICAST,UP&gt; mtu 1500 qdisc noqueue state DOWN qlen 1000 link/ether 52:54:00:2b:74:aa brd ff:ff:ff:ff:ff:ff inet 192.168.122.1/24 brd 192.168.122.255 scope global virbr0 valid_lft forever preferred_lft forever4: virbr0-nic: &lt;BROADCAST,MULTICAST&gt; mtu 1500 qdisc pfifo_fast master virbr0 state DOWN qlen 1000 link/ether 52:54:00:2b:74:aa brd ff:ff:ff:ff:ff:ff Step 2 启动Backup节点Nginx服务和Keepalived服务，查看服务启动情况，如Backup节点出现了虚拟IP，则Keepalvied配置文件有问题，此情况称为脑裂。 1234567891011121314151617181920[root@localhost keepalived]# clear[root@localhost keepalived]# ip add1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 65536 qdisc noqueue state UNKNOWN qlen 1 link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00 inet 127.0.0.1/8 scope host lo valid_lft forever preferred_lft forever inet6 ::1/128 scope host valid_lft forever preferred_lft forever2: ens33: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc pfifo_fast state UP qlen 1000 link/ether 00:0c:29:14:df:79 brd ff:ff:ff:ff:ff:ff inet 192.168.43.102/24 brd 192.168.43.255 scope global ens33 valid_lft forever preferred_lft forever inet6 fe80::314f:5fe7:4e4b:64ed/64 scope link valid_lft forever preferred_lft forever3: virbr0: &lt;NO-CARRIER,BROADCAST,MULTICAST,UP&gt; mtu 1500 qdisc noqueue state DOWN qlen 1000 link/ether 52:54:00:2b:74:aa brd ff:ff:ff:ff:ff:ff inet 192.168.122.1/24 brd 192.168.122.255 scope global virbr0 valid_lft forever preferred_lft forever4: virbr0-nic: &lt;BROADCAST,MULTICAST&gt; mtu 1500 qdisc pfifo_fast master virbr0 state DOWN qlen 1000 link/ether 52:54:00:2b:74:aa brd ff:ff:ff:ff:ff:ff Step 3 验证服务浏览并多次强制刷新地址： http://192.168.43.150 ,可以看到103和104多次交替显示，并显示Nginx-1,则表明 Master节点在进行web服务转发。 Step 4 关闭Master keepalived服务和Nginx服务，访问Web服务观察服务转移情况 12[root@localhost keepalived]# killall keepalived[root@localhost keepalived]# service nginx stop 此时强制刷新192.168.43.150发现 页面交替显示103和104并显示Nginx-2 ，VIP已转移到192.168.43.102上，已证明服务自动切换到备份节点上。 Step 5 启动Master Keepalived 服务和Nginx服务此时再次验证发现，VIP已被Master重新夺回，并页面交替显示 103和104，此时显示Nginx-1四、Keepalived抢占模式和非抢占模式keepalived的HA分为抢占模式和非抢占模式，抢占模式即MASTER从故障中恢复后，会将VIP从BACKUP节点中抢占过来。非抢占模式即MASTER恢复后不抢占BACKUP升级为MASTER后的VIP。 非抢占模式配置： 1&gt; 在vrrp_instance块下两个节点各增加了nopreempt指令，表示不争抢vip 2&gt; 节点的state都为BACKUP两个keepalived节点都启动后，默认都是BACKUP状态，双方在发送组播信息后，会根据优先级来选举一个MASTER出来。由于两者都配置了nopreempt，所以MASTER从故障中恢复后，不会抢占vip。这样会避免VIP切换可能造成的服务延迟。","tags":[]},{"title":"CentOS 7.2 安装Hive和Hive学习使用札记","date":"2018-02-01T06:02:28.037Z","path":"2018/02/01/CentOS_7.2_安装Hive和Hive学习使用札记/","text":"Hive由Facebook开源，是一个构建在Hadoop之上的数据仓库将结构化的数据映射成表支持类SQL查询，Hive中称为HQL无法实时更新，只支持向现有表中追加数据。 Hive原理图.png Hive常用文件格式类型TEXTFILE 默认文件格式，建表时用户需要显示指定分隔符 存储方式：行存储 SequenceFile 二进制键值对序列化文件格式 存储方式：行存储 列式存储格式 RCFILE/ORC 存储方式：列存储常用数据类型1.整数类型 SMALLINT、INT、BIGINT 空间占用分别是1字节、2字节、4字节、8字节2.浮点类型 DOUBLE 空间占用分别是32位和64位浮点数3. 布尔类型BOOLEAN 用于存储true和false4.字符串文本类型STRING 存储变长字符串，对类型长度没有限制5.时间戳类型TIMESTAMP 存储精度为纳秒的时间戳复杂数据类型1.ARRAY 存储相同类型的数据，可以通过下标获取数据 定义：ARRAY 查询：array[index]2.MAP 存储键值对数据，键或者值的类型必须相同，通过键获取值。 定义：MAP 查询：map[‘key’]3.STRUCT 可以存储多种不同的数据类型，一旦声明好结构，各字段的位置不能够改变。 定义：STRUCT 查询：struct.fieldname一、Hive的安装1.下载Hive安装包并解压 1[hadoop@hadoop01 apps]$ tar -zxvf apache-hive-1.2.2-bin.tar.gz 2.使用Root用户创建软链接1[root@hadoop01 apps]# ln -s /home/hadoop/apps/apache-hive-1.2.2-bin /usr/local/hive 3.为Hive指定用户组1[root@hadoop01 apps]# chown -R hadoop:hadoop /usr/local/hive 4. 添加Hive到系统环境变量并生效1[root@hadoop01 apps]# vim /etc/profile 添加环境变量内容为： 123export HIVE_HOME=/usr/local/hiveexport PATH=$PATH:$&#123;JAVA_HOME&#125;/bin:$&#123;ZOOKEEPER_HOME&#125;/bin:$&#123;HADOOP_HOME&#125;/bin:$&#123;HADOOP_HOME&#125;/sbin:$&#123;HIVE_HOME&#125;/bin 生效环境变量 1[root@hadoop01 apps]# source /etc/profile 5.配置Hive的默认metastore修改Hive配置目录下的hive-site.xml配置文件，编辑内容如下： 12345678910111213141516171819202122232425262728293031323334353637383940&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot; standalone=&quot;no&quot;?&gt;&lt;?xml-stylesheet type=&quot;text/xsl&quot; href=&quot;configuration.xsl&quot;?&gt;&lt;!-- Licensed to the Apache Software Foundation (ASF) under one or more contributor license agreements. See the NOTICE file distributed with this work for additional information regarding copyright ownership. The ASF licenses this file to You under the Apache License, Version 2.0 (the &quot;License&quot;); you may not use this file except in compliance with the License. You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0 Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an &quot;AS IS&quot; BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License.--&gt;&lt;configuration&gt; &lt;property&gt; &lt;name&gt;javax.jdo.option.ConnectionURL&lt;/name&gt; &lt;value&gt;jdbc:mysql://192.168.43.50:3306/hive?createDatabaseIfNotExist=true&amp;amp;characterEncoding=UTF-8&lt;/value&gt; &lt;description&gt;JDBC connect string for a JDBC metastore&lt;/description&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;javax.jdo.option.ConnectionDriverName&lt;/name&gt; &lt;value&gt;com.mysql.jdbc.Driver&lt;/value&gt; &lt;description&gt;Driver class name for a JDBC metastore&lt;/description&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;javax.jdo.option.ConnectionUserName&lt;/name&gt; &lt;value&gt;hadoop&lt;/value&gt; &lt;description&gt;username to use against metastore database&lt;/description&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;javax.jdo.option.ConnectionPassword&lt;/name&gt; &lt;value&gt;xxxx&lt;/value&gt; &lt;description&gt;password to use against metastore database&lt;/description&gt; &lt;/property&gt;&lt;/configuration&gt; 说明：数据库连接地址为Mysql地址，且所配置用户具有外网访问数据库权限,ConnectionPassword配置成个人Mysql数据库用户密码 二、Hive的使用1.运行hive123[hadoop@hadoop01 ~]$ hiveLogging initialized using configuration in jar:file:/home/hadoop/apps/apache-hive-1.2.2-bin/lib/hive-common-1.2.2.jar!/hive-log4j.properties 2.查看数据库1234hive&gt; show databases;OKdefaultTime taken: 0.99 seconds, Fetched: 1 row(s) 3.创建用户表： user_info字段信息 字段名称 字段类型 用户id string 地域id string 年龄 int 职业 string 123456789create table user_info(user_id string,area_id string,age int,occupation string)row format delimited fields terminated by &apos;\\t&apos; lines terminated by &apos;\\n&apos;stored as textfile; 4.查看表查看default库中的表，发现新建的user_info表在default库中 1234hive&gt; show tables;OKuser_infoTime taken: 0.04 seconds, Fetched: 1 row(s) 查看对应文件目录信息 123[hadoop@hadoop01 root]$ hadoop fs -ls /user/hive/warehouseFound 1 itemsdrwxr-xr-x - hadoop supergroup 0 2018-01-14 19:48 /user/hive/warehouse/user_info 5.hive删除表删除user_info表，user_info表在hdfs的目录也会被同时删除 123456hive&gt; drop table user_info;OKTime taken: 0.935 secondshive&gt; show tables;OKTime taken: 0.041 seconds 查看文件目录位置 12[hadoop@hadoop01 root]$ hadoop fs -ls /user/hive/warehouse[hadoop@hadoop01 root]$ 6.创建数据库，用于存储维度12345678hive&gt; create database rel;OKTime taken: 0.098 secondshive&gt; show databases;OKdefaultrelTime taken: 0.025 seconds, Fetched: 2 row(s) 查看对应文件目录信息： 123[hadoop@hadoop01 root]$ hadoop fs -ls /user/hive/warehouseFound 1 itemsdrwxr-xr-x - hadoop supergroup 0 2018-01-14 19:55 /user/hive/warehouse/rel.db 7.创建内部管理表在数据库rel中创建学生信息表，字段信息：学号、姓名、年龄、地域。切换使用rel数据库： 123456789101112use rel;create table student_info(student_id string comment &apos;学号&apos;,name string comment &apos;姓名&apos;,age int comment &apos;年龄&apos;,origin string comment &apos;地域&apos;)comment &apos;学生信息表&apos;row format delimited fields terminated by &apos;\\t&apos; lines terminated by &apos;\\n&apos;stored as textfile; 查看对应目录信息 123[hadoop@hadoop01 root]$ hadoop fs -ls /user/hive/warehouse/rel.dbFound 1 itemsdrwxr-xr-x - hadoop supergroup 0 2018-01-14 19:59 /user/hive/warehouse/rel.db/student_info 8.使用load从本地加载数据到表使用load从本地加载数据到表student_info 12345hive&gt; load data local inpath &apos;/home/hadoop/apps/hive_test_data/student_info_data.txt&apos; into table student_info;Loading data to table rel.student_infoTable rel.student_info stats: [numFiles=1, totalSize=341]OKTime taken: 1.144 seconds 查看student_info 表信息和对应文件路径 1234567891011121314151617181920212223hive&gt; select * from student_info;OK1 xiaoming 20 112 xiaobai 21 313 zhangfei 22 444 likui 19 445 zhaoyun 21 136 zhangsan 20 117 lisi 19 118 wangwu 23 319 zhaofei 19 2110 zhangyan 20 2111 lihe 20 2212 caoyang 17 3213 lihao 19 3214 zhaoming 21 5015 zhouhong 18 5116 yangshuo 23 3317 xiaofei 24 1318 liman 23 1319 qianbao 20 1320 sunce 21 41Time taken: 0.767 seconds, Fetched: 20 row(s) 查看对应文件夹路径信息 123[hadoop@hadoop01 hive_test_data]$ hadoop fs -ls /user/hive/warehouse/rel.db/student_infoFound 1 items-rwxr-xr-x 3 hadoop supergroup 341 2018-01-14 20:09 /user/hive/warehouse/rel.db/student_info/student_info_data.txt 9.使用load从HDFS上加载数据到表student_info先删除原有数据文件 123[hadoop@hadoop01 hive_test_data]$ hadoop fs -rm -f /user/hive/warehouse/rel.db/student_info/student_info_data.txt18/01/14 20:15:31 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.Deleted /user/hive/warehouse/rel.db/student_info/student_info_data.txt 将本地文件上传到HDFS根目录下 123456789[hadoop@hadoop01 hive_test_data]$ hadoop fs -put /home/hadoop/apps/hive_test_data/student_info_data.txt /[hadoop@hadoop01 hive_test_data]$ hadoop fs -ls /Found 6 itemsdrwxr-xr-x - hadoop supergroup 0 2018-01-14 16:23 /addatadrwxr-xr-x - hadoop supergroup 0 2017-12-23 20:20 /data-rw-r--r-- 3 hadoop supergroup 341 2018-01-14 20:16 /student_info_data.txtdrwxrwx--- - hadoop supergroup 0 2018-01-14 17:26 /tmpdrwxr-xr-x - hadoop supergroup 0 2018-01-14 19:48 /userdrwxr-xr-x - hadoop supergroup 0 2018-01-13 16:26 /wordcount 使用load将HDFS文件加载到student_info 表中 12345678910111213141516171819202122232425262728hive&gt; load data inpath &apos;/student_info_data.txt&apos; into table student_info;Loading data to table rel.student_infoTable rel.student_info stats: [numFiles=1, totalSize=341]OKTime taken: 0.602 secondshive&gt; select * from student_info;OK1 xiaoming 20 112 xiaobai 21 313 zhangfei 22 444 likui 19 445 zhaoyun 21 136 zhangsan 20 117 lisi 19 118 wangwu 23 319 zhaofei 19 2110 zhangyan 20 2111 lihe 20 2212 caoyang 17 3213 lihao 19 3214 zhaoming 21 5015 zhouhong 18 5116 yangshuo 23 3317 xiaofei 24 1318 liman 23 1319 qianbao 20 1320 sunce 21 41Time taken: 0.143 seconds, Fetched: 20 row(s) 采用覆盖重写方式加载文件到student_info 表中 原hdfs根目录下的student_info_data.txt已经被剪切到student_info表的hdfs路径下/user/hive/warehouse/rel.db/student_info12345hive&gt; load data inpath &apos;/student_info_data.txt&apos; overwrite into table student_info;Loading data to table rel.student_infoTable rel.student_info stats: [numFiles=1, numRows=0, totalSize=341, rawDataSize=0]OKTime taken: 0.41 seconds 10.Hive的数据类型 字段名 类型 注释 user_id string 用户ID salary int 工资 worked_citys array 工作过的城市 social_security map 社保缴费情况(养老，医保) wealfare struct 福利(吃饭补助(float),是否转正(boolean),商业保险(float) 创建员工表 12345678910111213141516171819hive&gt; create table rel.employee( &gt; user_id string, &gt; salary int, &gt; worked_citys array&lt;string&gt;, &gt; social_security map&lt;string,float&gt;, &gt; welfare struct&lt;meal_allowance:float,if_regular:boolean,commercial_insurance:float&gt; &gt; ) &gt; row format delimited fields terminated by &apos;\\t&apos; &gt; collection items terminated by &apos;,&apos; &gt; map keys terminated by &apos;:&apos; &gt; lines terminated by &apos;\\n&apos; &gt; stored as textfile;OKTime taken: 0.212 secondshive&gt; show tables;OKemployeestudent_infoTime taken: 0.057 seconds, Fetched: 2 row(s) 从本地加载数据到表employee 1234567891011hive&gt; load data local inpath &apos;/home/hadoop/apps/hive_test_data/employee_data.txt&apos; into table employee;Loading data to table rel.employeeTable rel.employee stats: [numFiles=1, totalSize=206]OKTime taken: 0.388 secondshive&gt; select * from employee;OKzhangsan 10800 [&quot;beijing&quot;,&quot;shanghai&quot;] &#123;&quot;养老&quot;:1000.0,&quot;医疗&quot;:600.0&#125; &#123;&quot;meal_allowance&quot;:2000.0,&quot;if_regular&quot;:true,&quot;commercial_insurance&quot;:500.0&#125;lisi 20000 [&quot;beijing&quot;,&quot;nanjing&quot;] &#123;&quot;养老&quot;:2000.0,&quot;医疗&quot;:1200.0&#125; &#123;&quot;meal_allowance&quot;:2000.0,&quot;if_regular&quot;:false,&quot;commercial_insurance&quot;:500.0&#125;wangwu 17000 [&quot;shanghai&quot;,&quot;nanjing&quot;] &#123;&quot;养老&quot;:1800.0,&quot;医疗&quot;:1100.0&#125; &#123;&quot;meal_allowance&quot;:2000.0,&quot;if_regular&quot;:true,&quot;commercial_insurance&quot;:500.0&#125;Time taken: 0.127 seconds, Fetched: 3 row(s) 查询已转正的员工编号，工资，工作过的第一个城市，社保养老缴费情况，福利餐补金额 1234567select user_id,salary,worked_citys[0],social_security[&apos;养老&apos;],welfare.meal_allowance from rel.employeewhere welfare.if_regular=true; 11.创建外部表 【常用】可以提前创建好hdfs路径hadoop mkdir -p /user/hive/warehouse/data/student_school_info如果没有提前创建好，在创建外部表的时候会根据指定路径自动创建|字段名|字段类型|字段注释||:—-:|:—-:|:—-:||student_id|string|学生ID||name|string|学生姓名||institute_id|string|学院ID||major_id|string|专业ID||school_year|string|入学年份| 123456789101112create external table rel.student_school_info(student_id string,name string,institute_id string,major_id string,school_year string)row format delimited fields terminated by &apos;\\t&apos; lines terminated by &apos;\\n&apos;stored as textfilelocation &apos;/user/hive/warehouse/data/student_school_info&apos;; 查看对应文件目录 123[hadoop@hadoop01 root]$ hadoop fs -ls /user/hive/warehouse/data/Found 1 itemsdrwxr-xr-x - hadoop supergroup 0 2018-01-15 14:08 /user/hive/warehouse/data/student_school_info 上传本地数据文件到hdfs 1[hadoop@hadoop01 root]$ hadoop fs -put /home/hadoop/apps/hive_test_data/student_school_info_external_data.txt /user/hive/warehouse/data/student_school_info/ 12.创建内部分区表 字段名称 类型 注释 studnet_id string 学号 name string 姓名 institute_id string 学院ID major_id string 专业ID 1234567891011create table student_school_info_partition(student_id string,name string,institute_id string,major_id string)partitioned by(school_year string) row format delimitedfields terminated by &apos;\\t&apos; lines terminated by &apos;\\n&apos;stored as textfile; 使用insert into从student_school_info表将2017年入学的学籍信息导入到student_school_info_partition分区表中 1234insert into table student_school_info_partition partition(school_year=&apos;2017&apos;)select t1.student_id,t1.name,t1.institute_id,t1.major_idfrom student_school_info t1where t1.school_year=2017; 13.查看分区1234hive&gt; show partitions student_school_info_partition;OKschool_year=2017Time taken: 0.191 seconds, Fetched: 1 row(s) 查看hdfs路径 123[hadoop@hadoop01 root]$ hadoop fs -ls /user/hive/warehouse/rel.db/student_school_info_partition/Found 1 itemsdrwxr-xr-x - hadoop supergroup 0 2018-01-16 13:20 /user/hive/warehouse/rel.db/student_school_info_partition/school_year=2017 查询student_school_info_partition 1234567891011hive&gt; select * from student_school_info_partition where school_year=&apos;2017&apos;;OK1 xiaoming information software 20172 xiaobai information computer 20173 zhangfei information computer 20174 likui information bigdata 20175 zhaoyun information bigdata 20176 zhangsan information software 20177 lisi information bigdata 20178 wangwu information computer 2017Time taken: 0.226 seconds, Fetched: 8 row(s) 14.删除分区1234hive&gt; alter table student_school_info_partition drop partition (school_year=&apos;2017&apos;);Dropped the partition school_year=2017OKTime taken: 0.71 seconds 15.使用动态分区添加数据12345set hive.exec.dynamic.partition=true;set hive.exec.dynamic.partition.mode=nonstrict;insert overwrite table student_school_info_partition partition(school_year)select t1.student_id,t1.name,t1.institute_id,t1.major_id,t1.school_yearfrom student_school_info t1 查看分区 1234hive&gt; show partitions student_school_info_partition;OKschool_year=2017Time taken: 0.12 seconds, Fetched: 1 row(s) 查看hdfs路径 123[hadoop@hadoop01 root]$ hadoop fs -ls /user/hive/warehouse/rel.db/student_school_info_partition/Found 1 itemsdrwxr-xr-x - hadoop supergroup 0 2018-01-16 13:27 /user/hive/warehouse/rel.db/student_school_info_partition/school_year=2017 15.创建外部分区表【常用】123456789101112create external table rel.student_school_info_external_partition(student_id string,name string,institute_id string,major_id string)partitioned by(school_year string) row format delimited fields terminated by &apos;\\t&apos; lines terminated by &apos;\\n&apos;stored as textfilelocation &apos;/user/hive/warehouse/data/student_school_info_external_partition&apos;; 在分区表的hdfs路径中添加school_year=2017目录 1hadoop fs -mkdir /user/hive/warehouse/data/student_school_info_external_partition/school_year=2017 将student_school_external_partition_data.txt文件上传到school_year=2017文件夹下 1hadoop fs -put student_school_external_partition_data.txt /user/hive/warehouse/data/student_school_info_external_partition/school_year=2017 虽然数据已经添加到了分区对应的hdfs路径，但是表还没有添加分区，所以查询的时候没有数据 手动添加分区 123hive&gt; alter table student_school_info_external_partition add partition(school_year=&apos;2017&apos;);OKTime taken: 0.111 seconds 1234567891011hive&gt; select * from student_school_info_external_partition;OK1 xiaoming information software 20172 xiaobai information computer 20173 zhangfei information computer 20174 likui information bigdata 20175 zhaoyun information bigdata 20176 zhangsan information software 20177 lisi information bigdata 20178 wangwu information computer 2017Time taken: 0.127 seconds, Fetched: 8 row(s) 删除分区 1234hive&gt; alter table student_school_info_external_partition drop partition(school_year=&apos;2017&apos;);Dropped the partition school_year=2017OKTime taken: 0.19 seconds 查看分区，分区已经被删除 123hive&gt; show partitions student_school_info_external_partition;OKTime taken: 0.168 seconds 查看hdfs分区数据，分区数据还在 123[hadoop@hadoop01 hive_test_data]$ hadoop fs -ls /user/hive/warehouse/data/student_school_info_external_partition/school_year=2017Found 1 items-rw-r--r-- 3 hadoop supergroup 250 2018-01-16 13:33 /user/hive/warehouse/data/student_school_info_external_partition/school_year=2017/student_school_external_partition_data.txt","tags":[]},{"title":"Centos7.2安装MariaDB","date":"2018-02-01T06:01:37.203Z","path":"2018/02/01/Centos7.2安装MariaDB/","text":"1.检查是否已经具有MariaDB相关安装，并删除已有安装12[root@hadoop01 home]# rpm -qa|grep mariadb #查询已安装包mariadb-libs-5.5.52-1.el7.x86_64 12[root@hadoop01 home]# rpm -e --nodeps mariadb-* # 移除已安装包错误：未安装软件包 mariadb-* 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950[root@hadoop01 home]# yum remove mysql mysql-server mysql-libs compat-mysql51 # 删除Mysql服务已加载插件：fastestmirror, langpacks参数 mysql 没有匹配参数 mysql-server 没有匹配参数 compat-mysql51 没有匹配正在解决依赖关系--&gt; 正在检查事务---&gt; 软件包 mariadb-libs.x86_64.1.5.5.52-1.el7 将被 删除--&gt; 正在处理依赖关系 libmysqlclient.so.18()(64bit)，它被软件包 2:postfix-2.10.1-6.el7.x86_64 需要--&gt; 正在处理依赖关系 libmysqlclient.so.18(libmysqlclient_18)(64bit)，它被软件包 2:postfix-2.10.1-6.el7.x86_64 需要--&gt; 正在检查事务---&gt; 软件包 postfix.x86_64.2.2.10.1-6.el7 将被 删除 &gt; 解决依赖关系完成▽ase/7/x86_64 | 3.6 kB 00:00:00 extras/7/x86_64 | 3.4 kB 00:00:00 updates/7/x86_64 | 3.4 kB 00:00:00 依赖关系解决============================================================================================================================================================================================================================================ Package 架构 版本 源 大小============================================================================================================================================================================================================================================正在删除: mariadb-libs x86_64 1:5.5.52-1.el7 @anaconda 4.4 M为依赖而移除: postfix x86_64 2:2.10.1-6.el7 @anaconda 12 M事务概要============================================================================================================================================================================================================================================移除 1 软件包 (+1 依赖软件包)安装大小：17 M是否继续？[y/N]：yDownloading packages:Running transaction checkRunning transaction testTransaction test succeededRunning transaction 正在删除 : 2:postfix-2.10.1-6.el7.x86_64 1/2 正在删除 : 1:mariadb-libs-5.5.52-1.el7.x86_64 2/2 验证中 : 2:postfix-2.10.1-6.el7.x86_64 1/2 验证中 : 1:mariadb-libs-5.5.52-1.el7.x86_64 2/2 删除: mariadb-libs.x86_64 1:5.5.52-1.el7 作为依赖被删除: postfix.x86_64 2:2.10.1-6.el7 完毕！ 2.增加MariaDB的仓库源12345678[root@hadoop01 home]#vi /etc/yum.repos.d/MariaDB.repo 增加MariaDB的数据库镜像信息# MariaDB 10.2 CentOS repository list - created 2017-12-26 06:46 UTC# http://downloads.mariadb.org/mariadb/repositories/[mariadb]name = MariaDBbaseurl = http://yum.mariadb.org/10.2/centos7-amd64gpgkey=https://yum.mariadb.org/RPM-GPG-KEY-MariaDBgpgcheck=1 文件信息请参考[https://downloads.mariadb.org/mariadb/repositories/#mirror=tuna] 设置具体需要安装的版本，本文下载MariaDB10.2稳定版。 3.安装MariaDB123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263[root@localhost ~]# yum -y install MariaDB-server MariaDB-client已加载插件：fastestmirror, langpacksmariadb | 2.9 kB 00:00:00 mariadb/primary_db | 21 kB 00:00:01 Loading mirror speeds from cached hostfile * base: mirrors.aliyun.com * extras: mirrors.sohu.com * updates: mirrors.aliyun.com正在解决依赖关系--&gt; 正在检查事务---&gt; 软件包 MariaDB-client.x86_64.0.10.2.11-1.el7.centos 将被 安装--&gt; 正在处理依赖关系 MariaDB-common，它被软件包 MariaDB-client-10.2.11-1.el7.centos.x86_64 需要---&gt; 软件包 MariaDB-server.x86_64.0.10.2.11-1.el7.centos 将被 安装--&gt; 正在处理依赖关系 perl(DBI)，它被软件包 MariaDB-server-10.2.11-1.el7.centos.x86_64 需要--&gt; 正在处理依赖关系 galera，它被软件包 MariaDB-server-10.2.11-1.el7.centos.x86_64 需要--&gt; 正在检查事务---&gt; 软件包 MariaDB-common.x86_64.0.10.2.11-1.el7.centos 将被 安装--&gt; 正在处理依赖关系 MariaDB-compat，它被软件包 MariaDB-common-10.2.11-1.el7.centos.x86_64 需要---&gt; 软件包 galera.x86_64.0.25.3.22-1.rhel7.el7.centos 将被 安装--&gt; 正在处理依赖关系 libboost_program_options.so.1.53.0()(64bit)，它被软件包 galera-25.3.22-1.rhel7.el7.centos.x86_64 需要---&gt; 软件包 perl-DBI.x86_64.0.1.627-4.el7 将被 安装--&gt; 正在处理依赖关系 perl(RPC::PlServer) &gt;= 0.2001，它被软件包 perl-DBI-1.627-4.el7.x86_64 需要--&gt; 正在处理依赖关系 perl(RPC::PlClient) &gt;= 0.2000，它被软件包 perl-DBI-1.627-4.el7.x86_64 需要--&gt; 正在检查事务---&gt; 软件包 MariaDB-compat.x86_64.0.10.2.11-1.el7.centos 将被 安装---&gt; 软件包 boost-program-options.x86_64.0.1.53.0-27.el7 将被 安装---&gt; 软件包 perl-PlRPC.noarch.0.0.2020-14.el7 将被 安装--&gt; 正在处理依赖关系 perl(Net::Daemon) &gt;= 0.13，它被软件包 perl-PlRPC-0.2020-14.el7.noarch 需要--&gt; 正在处理依赖关系 perl(Net::Daemon::Test)，它被软件包 perl-PlRPC-0.2020-14.el7.noarch 需要--&gt; 正在处理依赖关系 perl(Net::Daemon::Log)，它被软件包 perl-PlRPC-0.2020-14.el7.noarch 需要--&gt; 正在处理依赖关系 perl(Compress::Zlib)，它被软件包 perl-PlRPC-0.2020-14.el7.noarch 需要--&gt; 正在检查事务---&gt; 软件包 perl-IO-Compress.noarch.0.2.061-2.el7 将被 安装--&gt; 正在处理依赖关系 perl(Compress::Raw::Zlib) &gt;= 2.061，它被软件包 perl-IO-Compress-2.061-2.el7.noarch 需要--&gt; 正在处理依赖关系 perl(Compress::Raw::Bzip2) &gt;= 2.061，它被软件包 perl-IO-Compress-2.061-2.el7.noarch 需要---&gt; 软件包 perl-Net-Daemon.noarch.0.0.48-5.el7 将被 安装--&gt; 正在检查事务---&gt; 软件包 perl-Compress-Raw-Bzip2.x86_64.0.2.061-3.el7 将被 安装---&gt; 软件包 perl-Compress-Raw-Zlib.x86_64.1.2.061-4.el7 将被 安装--&gt; 解决依赖关系完成依赖关系解决============================================================================================================================================================================================================================================ Package 架构 版本 源 大小============================================================================================================================================================================================================================================正在安装: MariaDB-client x86_64 10.2.11-1.el7.centos mariadb 48 M MariaDB-server x86_64 10.2.11-1.el7.centos mariadb 110 M为依赖而安装: MariaDB-common x86_64 10.2.11-1.el7.centos mariadb 154 k MariaDB-compat x86_64 10.2.11-1.el7.centos mariadb 2.8 M boost-program-options x86_64 1.53.0-27.el7 base 156 k galera x86_64 25.3.22-1.rhel7.el7.centos mariadb 8.0 M perl-Compress-Raw-Bzip2 x86_64 2.061-3.el7 base 32 k perl-Compress-Raw-Zlib x86_64 1:2.061-4.el7 base 57 k perl-DBI x86_64 1.627-4.el7 base 802 k perl-IO-Compress noarch 2.061-2.el7 base 260 k perl-Net-Daemon noarch 0.48-5.el7 base 51 k perl-PlRPC noarch 0.2020-14.el7 base 36 k事务概要============================================================================================================================================================================================================================================ 等待下载完成,下载完成后会自动安装。 4.MariaDB服务管理12345[root@hadoop01 home]# systemctl start mariadb # 开启数据库服务[root@hadoop01 home]# systemctl enable mariadb # 开机自启动[root@hadoop01 home]# systemctl restart mariadb # 重启服务 [root@hadoop01 home]# systemctl status mariadb #查看数据库状态[root@hadoop01 home]# systemctl stop mariadb.service # 停止数据库服务 5.数据库登录12345678910[root@hadoop01 home]# mysql -urootWelcome to the MariaDB monitor. Commands end with ; or \\g.Your MariaDB connection id is 8Server version: 10.2.11-MariaDB MariaDB ServerCopyright (c) 2000, 2017, Oracle, MariaDB Corporation Ab and others.Type &apos;help;&apos; or &apos;\\h&apos; for help. Type &apos;\\c&apos; to clear the current input statement.MariaDB [(none)]&gt; 6.设置数据库密码123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263[root@hadoop01 home]# mysql_secure_installation #初始化密码NOTE: RUNNING ALL PARTS OF THIS SCRIPT IS RECOMMENDED FOR ALL MariaDB SERVERS IN PRODUCTION USE! PLEASE READ EACH STEP CAREFULLY!In order to log into MariaDB to secure it, we&apos;ll need the currentpassword for the root user. If you&apos;ve just installed MariaDB, andyou haven&apos;t set the root password yet, the password will be blank,so you should just press enter here.Enter current password for root (enter for none): #输入当前密码，一般没设置直接回车ERROR 1045 (28000): Access denied for user &apos;root&apos;@&apos;localhost&apos; (using password: YES)Enter current password for root (enter for none): OK, successfully used password, moving on...Setting the root password ensures that nobody can log into the MariaDBroot user without the proper authorisation.Set root password? [Y/n] y #是否设置root密码，输入yNew password: #输入新密码Re-enter new password: #重复密码 Password updated successfully!Reloading privilege tables.. ... Success!By default, a MariaDB installation has an anonymous user, allowing anyoneto log into MariaDB without having to have a user account created forthem. This is intended only for testing, and to make the installationgo a bit smoother. You should remove them before moving into aproduction environment.Remove anonymous users? [Y/n] #删除匿名用户 y ... Success!Normally, root should only be allowed to connect from &apos;localhost&apos;. Thisensures that someone cannot guess at the root password from the network.Disallow root login remotely? [Y/n] #禁止root远程登录 ... Success!By default, MariaDB comes with a database named &apos;test&apos; that anyone canaccess. This is also intended only for testing, and should be removedbefore moving into a production environment.Remove test database and access to it? [Y/n] #是否删除test数据库 - Dropping test database... ... Success! - Removing privileges on test database... ... Success!Reloading the privilege tables will ensure that all changes made so farwill take effect immediately.Reload privilege tables now? [Y/n] #是否重新加载权限表 ... Success!Cleaning up...All done! If you&apos;ve completed all of the above steps, your MariaDBinstallation should now be secure.Thanks for using MariaDB! 测试登录1234567891011[root@hadoop01 home]# mysql -uroot -pEnter password: Welcome to the MariaDB monitor. Commands end with ; or \\g.Your MariaDB connection id is 22Server version: 10.2.11-MariaDB MariaDB ServerCopyright (c) 2000, 2017, Oracle, MariaDB Corporation Ab and others.Type &apos;help;&apos; or &apos;\\h&apos; for help. Type &apos;\\c&apos; to clear the current input statement.MariaDB [(none)]&gt; 7.配置MariaDB数据库字符集1234[root@hadoop01 home]# cd /etc/my.cnf.d/[root@hadoop01 my.cnf.d]# lsenable_encryption.preset mysql-clients.cnf server.cnf[root@hadoop01 my.cnf.d]# vim server.cnf (1).在server.cnf 文件在[mysqld]标签下增加以下信息：12345init_connect=&apos;SET collation_connection = utf8_unicode_ci&apos; init_connect=&apos;SET NAMES utf8&apos; character-set-server=utf8 collation-server=utf8_unicode_ci skip-character-set-client-handshake (2).在mysql-clients.cnf 文件[mysql]标签下增加如下信息：1default-character-set=utf8 全部配置完成后重启数据库服务1[root@hadoop01 my.cnf.d]# systemctl restart mariadb 之后进入MariaDB查看字符集123456789101112131415161718192021222324252627282930313233343536[root@hadoop01 my.cnf.d]# systemctl restart mariadb[root@hadoop01 my.cnf.d]# mysql -uroot -pEnter password: Welcome to the MariaDB monitor. Commands end with ; or \\g.Your MariaDB connection id is 9Server version: 10.2.11-MariaDB MariaDB ServerCopyright (c) 2000, 2017, Oracle, MariaDB Corporation Ab and others.Type &apos;help;&apos; or &apos;\\h&apos; for help. Type &apos;\\c&apos; to clear the current input statement.MariaDB [(none)]&gt; show variables like &quot;%character%&quot;;show variables like &quot;%collation%&quot;;+--------------------------+----------------------------+| Variable_name | Value |+--------------------------+----------------------------+| character_set_client | utf8 || character_set_connection | utf8 || character_set_database | utf8 || character_set_filesystem | binary || character_set_results | utf8 || character_set_server | utf8 || character_set_system | utf8 || character_sets_dir | /usr/share/mysql/charsets/ |+--------------------------+----------------------------+8 rows in set (0.00 sec)+----------------------+-----------------+| Variable_name | Value |+----------------------+-----------------+| collation_connection | utf8_unicode_ci || collation_database | utf8_unicode_ci || collation_server | utf8_unicode_ci |+----------------------+-----------------+3 rows in set (0.00 sec)MariaDB [(none)]&gt; 字符集配置完成 8.创建用户、添加授权(1).创建用户12MariaDB [(none)]&gt; create user hadoop@localhost identified by &apos;xxxx&apos;; #请替换xx为密码Query OK, 0 rows affected (0.01 sec) (2).为用户进行操作授权12MariaDB [(none)]&gt; grant all on *.* to hadoop@locahost identified by &apos;xxxx&apos;; #请替换xx为密码Query OK, 0 rows affected (0.00 sec) (3).授权外网登录权限12MariaDB [(none)]&gt; grant all privileges on *.* to hadoop@&apos;%&apos; identified by &apos;xxx&apos;; #请替换xx为密码Query OK, 0 rows affected (0.00 sec) 查询用户授权结果123456789101112MariaDB [mysql]&gt; select host,user,password from user;+-----------+--------+-------------------------------------------+| host | user | password |+-----------+--------+-------------------------------------------+| localhost | root | *7D8990305DAAE2A688433D400E6559EBDF439529 || 127.0.0.1 | root | *7D8990305DAAE2A688433D400E6559EBDF439529 || ::1 | root | *7D8990305DAAE2A688433D400E6559EBDF439529 || locahost | hadoop | *7D8990305DAAE2A688433D400E6559EBDF439529 || localhost | hadoop | *AB7E9F716159ED905A3E5DA78DA0DFD516C429E1 || % | hadoop | *7D8990305DAAE2A688433D400E6559EBDF439529 |+-----------+--------+-------------------------------------------+6 rows in set (0.00 sec)","tags":[]},{"title":"java 实现FastDFS文件操作","date":"2018-02-01T05:59:44.984Z","path":"2018/02/01/java_实现FastDFS文件操作/","text":"java 实现FastDFS 文件操作1.下载FastClient并实现依赖Jar安装访问余大github项目 地址为fastdfs-client-java下载后导入Idea，修改项目Java编译版本，如图所示： fastDFS java项目截图 使用Maven进行 编译和构建，dos窗口定位到该项目路径下，进行编译和构建 1E:\\fastdfs-client-java-master&gt;mvn clean install 构建成功后，会在maven 本地仓库出现相关Jar包，如图所示： 依赖Jar构建成功 在需要进行文件操作的项目模块增加Pom文件依赖配置，配置内容如下： 123456&lt;!-- fastdfs上传下载图片 路径和上面的pom中对应 --&gt; &lt;dependency&gt; &lt;groupId&gt;org.csource.fastdfs-client-java&lt;/groupId&gt; &lt;artifactId&gt;fastdfs-client-java&lt;/artifactId&gt; &lt;version&gt;1.27&lt;/version&gt; &lt;/dependency&gt; 2.增加FastDFS连接配置文件在需要的项目模块资源配置文件夹下 src/resource 目录下新增配置文件 fdfs_client.properties配置内容具体如下： 1234567connect_timeout = 2network_timeout = 30charset = UTF-8http.tracker_http_port = 8088 # tracker Http端口http.anti_steal_token = no # 暂无作用http.secret_key = FastDFS1234567890 # 暂无作用tracker_server = 192.168.43.60:22122 # tracker Server地址信息 3.编写FastClient 工具类，用于封装文件操作123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211package com.gsww.ctyxy.util;import org.csource.common.MyException;import org.csource.common.NameValuePair;import org.csource.fastdfs.*;import java.io.BufferedOutputStream;import java.io.IOException;import java.net.URLDecoder;/** * FastDFS工具类【实现文件上传、下载、删除、查询】 * @author Zhangyongliang */public class FastDFSClient &#123; private TrackerClient trackerClient = null; private TrackerServer trackerServer = null; private StorageServer storageServer = null; private StorageClient1 storageClient = null; public FastDFSClient(String conf) throws Exception &#123; if (conf.contains(&quot;classpath:&quot;)) &#123; String path = URLDecoder.decode(getClass().getProtectionDomain().getCodeSource().getLocation().toString(),&quot;UTF-8&quot;); path=path.substring(6); conf = conf.replace(&quot;classpath:&quot;,URLDecoder.decode(path,&quot;UTF-8&quot;)); &#125; ClientGlobal.init(conf); trackerClient = new TrackerClient(); trackerServer = trackerClient.getConnection(); storageServer = null; storageClient = new StorageClient1(trackerServer, storageServer); &#125; /** * 上传文件方法 * &lt;p&gt;Title: uploadFile&lt;/p&gt; * &lt;p&gt;Description: &lt;/p&gt; * @param fileName 文件全路径 * @param extName 文件扩展名，不包含（.） * @param metas 文件扩展信息 * @return * @throws Exception */ public String uploadFile(String fileName, String extName, NameValuePair[] metas) &#123; String result=null; try &#123; result = storageClient.upload_file1(fileName, extName, metas); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; catch (MyException e) &#123; e.printStackTrace(); &#125; return result; &#125; /** * 上传文件,传fileName * @param fileName 文件的磁盘路径名称 如：D:/image/aaa.jpg * @return null为失败 */ public String uploadFile(String fileName) &#123; return uploadFile(fileName, null, null); &#125; /** * * @param fileName 文件的磁盘路径名称 如：D:/image/aaa.jpg * @param extName 文件的扩展名 如 txt jpg等 * @return null为失败 */ public String uploadFile(String fileName, String extName) &#123; return uploadFile(fileName, extName, null); &#125; /** * 上传文件方法 * &lt;p&gt;Title: uploadFile&lt;/p&gt; * &lt;p&gt;Description: &lt;/p&gt; * @param fileContent 文件的内容，字节数组 * @param extName 文件扩展名 * @param metas 文件扩展信息 * @return * @throws Exception */ public String uploadFile(byte[] fileContent, String extName, NameValuePair[] metas) &#123; String result=null; try &#123; result = storageClient.upload_file1(fileContent, extName, metas); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; catch (MyException e) &#123; e.printStackTrace(); &#125; return result; &#125; /** * 上传文件 * @param fileContent 文件的字节数组 * @return null为失败 * @throws Exception */ public String uploadFile(byte[] fileContent) throws Exception &#123; return uploadFile(fileContent, null, null); &#125; /** * 上传文件 * @param fileContent 文件的字节数组 * @param extName 文件的扩展名 如 txt jpg png 等 * @return null为失败 */ public String uploadFile(byte[] fileContent, String extName) &#123; return uploadFile(fileContent, extName, null); &#125; /** * 文件下载到磁盘 * @param path 图片路径 * @param output 输出流 中包含要输出到磁盘的路径 * @return -1失败,0成功 */ public int download_file(String path,BufferedOutputStream output) &#123; int result=-1; try &#123; byte[] b = storageClient.download_file1(path); try&#123; if(b != null)&#123; output.write(b); result=0; &#125; &#125;catch (Exception e)&#123;&#125; //用户可能取消了下载 finally &#123; if (output != null)&#123; try &#123; output.close(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125; &#125; &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; return result; &#125; /** * 获取文件数组 * @param path 文件的路径 如group1/M00/00/00/wKgRsVjtwpSAXGwkAAAweEAzRjw471.jpg * @return */ public byte[] download_bytes(String path) &#123; byte[] b=null; try &#123; b = storageClient.download_file1(path); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; catch (MyException e) &#123; e.printStackTrace(); &#125; return b; &#125; /** * 删除文件 * @param group 组名 如：group1 * @param storagePath 不带组名的路径名称 如：M00/00/00/wKgRsVjtwpSAXGwkAAAweEAzRjw471.jpg * @return -1失败,0成功 */ public Integer delete_file(String group ,String storagePath)&#123; int result=-1; try &#123; result = storageClient.delete_file(group, storagePath); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; catch (MyException e) &#123; e.printStackTrace(); &#125; return result; &#125; /** * * @param storagePath 文件的全部路径 如：group1/M00/00/00/wKgRsVjtwpSAXGwkAAAweEAzRjw471.jpg * @return -1失败,0成功 * @throws IOException * @throws Exception */ public Integer delete_file(String storagePath)&#123; int result=-1; try &#123; result = storageClient.delete_file1(storagePath); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; catch (MyException e) &#123; e.printStackTrace(); &#125; return result; &#125; /** * 获取远程服务器文件资源信息 * @param groupName 文件组名 如：group1 * @param remoteFileName M00/00/00/wKgRsVjtwpSAXGwkAAAweEAzRjw471.jpg * @return */ public FileInfo getFile(String groupName,String remoteFileName)&#123; try &#123; return storageClient.get_file_info(groupName, remoteFileName); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; return null; &#125;&#125; 4.文件操作在web 项目Controller层进行文件的操作 上传文件12345678910@RequestMapping(value = &quot;file/uploadFast&quot;,method = RequestMethod.GET)public void uploadFast(HttpServletRequest request)throws Exception&#123; // 1、把FastDFS提供的jar包添加到工程中 // 2、初始化全局配置。加载一个配置文件。 String confUrl=this.getClass().getClassLoader().getResource(&quot;/fdfs_client.properties&quot;).getPath(); FastDFSClient fastDFSClient=new FastDFSClient(confUrl); //上传文件 String filePath= fastDFSClient.uploadFile(&quot;F:\\\\Photos\\\\P70602-192547.jpg&quot;); System.out.println(&quot;返回路径：&quot;+filePath); //省略其他 删除文件 123//删除文件 int flag=fastDFSClient.delete_file(&quot;group1/M00/00/00/wKgrPFpf94KASn3vAAsC7gailiI018.jpg&quot;); System.out.println(&quot;删除结果：&quot; +(flag==0?&quot;删除成功&quot;:&quot;删除失败&quot;)); 下载文件到桌面 12345//下载文件到用户桌面位置 FileSystemView fsv = FileSystemView.getFileSystemView(); File com=fsv.getHomeDirectory(); //读取桌面路径 int downFlag=fastDFSClient.download_file(&quot;group1/M00/00/00/wKgrPFpe9OqAWsHxAAH5yvc2jn8251.jpg&quot;,new BufferedOutputStream(new FileOutputStream(com.getPath()+&quot;\\\\aa.jpg&quot;))); System.out.println(&quot;下载结果为：&quot; +(downFlag==0?&quot;下载文件成功&quot;:&quot;下载文件失败&quot;)); 查询文件信息 123//获取文件信息 FileInfo file=fastDFSClient.getFile(&quot;group1&quot;,&quot;M00/00/00/wKgrPFpe9OqAWsHxAAH5yvc2jn8251.jpg&quot;); System.out.println(&quot;获取文件信息成功：&quot;+file.getFileSize()); 说明：在FastDFS工具类中集合了支持字节数组的上传入参。","tags":[]},{"title":"Kafka集群的安装部署和实践应用","date":"2018-02-01T05:58:55.363Z","path":"2018/02/01/Kafka集群的安装部署和实践应用/","text":"Kafka介绍Kafka是一种高吞吐量的分布式发布订阅消息系统，有如下特性： 通过O(1)的磁盘数据结构提供消息的持久化，这种结构对于即使数以TB的消息存储也能够保持长时间的稳定性能。 高吞吐量：即使是非常普通的硬件Kafka也可以支持每秒数百万的消息。 支持通过Kafka服务器和消费机集群来分区消息。 支持Hadoop并行数据加载。消息队列的作用 应用程序解耦并行处理 顺序保证 高吞吐率 高容错、高可用 可扩展 峰值处理 Kafka集群.png kafka原理Kafka集群由多个实例组成，每个节点称为Broker，对消息保存时根据Topic进行归类一个Topic可以被划分为多个Partition每个Partition可以有多个副本。 Kafka原理图01.png Partition内顺序存储，写入新消息采用追加的方式，消费消息采用FIFO的方式顺序拉取消息一个Topic可以有多个分区，Kafka只保证同一个分区内有序，不保证Topic整体（多个分区之间）有序 kafka原理图02.png Consumer Group（CG），为了加快读取速度，多个consumer可以划分为一个组，并行消费一个Toic,一个Topic可以由多个CG订阅，多个CG之间是平等的，同一个CG内可以有一个或多个consumer，同一个CG内的consumer之间是竞争 关系，一个消息在一个CG内的只能被一个consumer消费 kafka原理图03.png 一、Kafka集群部署集群规划清单 名称 节点 说明 节点名 Broker01 192.168.43.22 kafka节点01 hadoop03 Broker02 192.168.43.23 kafka节点02 hadoop04 Broker03 192.168.43.24 kafka节点03 hadoop05 Zookeeper 192.168.43.20/21/22 Zookeeper集群节点 hadoop01/hadoop02/hadoop03 1.下载Kafka安装包,并解压安装12345678910[root@hadoop03 kafka_2.11-0.10.2.1]# ll总用量 52drwxr-xr-x. 3 hadoop hadoop 4096 4月 22 2017 bindrwxr-xr-x. 2 hadoop hadoop 4096 4月 22 2017 configdrwxr-xr-x. 2 root root 152 1月 20 18:57 kafka-logsdrwxr-xr-x. 2 hadoop hadoop 4096 1月 20 18:43 libs-rw-r--r--. 1 hadoop hadoop 28824 4月 22 2017 LICENSEdrwxr-xr-x. 2 root root 4096 1月 20 23:07 logs-rw-r--r--. 1 hadoop hadoop 336 4月 22 2017 NOTICEdrwxr-xr-x. 2 hadoop hadoop 47 4月 22 2017 site-docs 2.创建软链接1[root@hadoop03 kafka_2.11-0.10.2.1]# ln -s /home/hadoop/apps/kafka_2.11-0.10.2.1 /usr/local/kafka 3.创建日志文件夹123[root@hadoop03 kafka]# pwd/usr/local/kafka[root@hadoop03 kafka]# mkdir kafka-logs/ 4.配置服务启动信息在/usr/local/kafka/config目录下修改server.properties文件，具体内容如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105# Licensed to the Apache Software Foundation (ASF) under one or more# contributor license agreements. See the NOTICE file distributed with# this work for additional information regarding copyright ownership.# The ASF licenses this file to You under the Apache License, Version 2.0# (the &quot;License&quot;); you may not use this file except in compliance with# the License. You may obtain a copy of the License at## http://www.apache.org/licenses/LICENSE-2.0## Unless required by applicable law or agreed to in writing, software# distributed under the License is distributed on an &quot;AS IS&quot; BASIS,# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.# See the License for the specific language governing permissions and# limitations under the License.# see kafka.server.KafkaConfig for additional details and defaults############################# Server Basics ##############################每个borker的id是唯一的，多个broker要设置不同的idbroker.id=0#访问端口号port=9092#访问地址host.name=192.168.43.22#允许删除topicdelete.topic.enable=true# The number of threads handling network requestsnum.network.threads=3# The number of threads doing disk I/Onum.io.threads=8# The send buffer (SO_SNDBUF) used by the socket serversocket.send.buffer.bytes=102400# The receive buffer (SO_RCVBUF) used by the socket serversocket.receive.buffer.bytes=102400# The maximum size of a request that the socket server will accept (protection against OOM)socket.request.max.bytes=104857600############################# Log Basics ##############################存储数据路径，默认是在/tmp目录下，需要修改log.dirs=/usr/local/kafka/kafka-logs#创建topic默认分区数num.partitions=1# The number of threads per data directory to be used for log recovery at startup and flushing at shutdown.# This value is recommended to be increased for installations with data dirs located in RAID array.num.recovery.threads.per.data.dir=1############################# Log Flush Policy ############################## Messages are immediately written to the filesystem but by default we only fsync() to sync# the OS cache lazily. The following configurations control the flush of data to disk.# There are a few important trade-offs here:# 1. Durability: Unflushed data may be lost if you are not using replication.# 2. Latency: Very large flush intervals may lead to latency spikes when the flush does occur as there will be a lot of data to flush.# 3. Throughput: The flush is generally the most expensive operation, and a small flush interval may lead to exceessive seeks.# The settings below allow one to configure the flush policy to flush data after a period of time or# every N messages (or both). This can be done globally and overridden on a per-topic basis.# The number of messages to accept before forcing a flush of data to disk#log.flush.interval.messages=10000# The maximum amount of time a message can sit in a log before we force a flush#log.flush.interval.ms=1000############################# Log Retention Policy ############################## The following configurations control the disposal of log segments. The policy can# be set to delete segments after a period of time, or after a given size has accumulated.# A segment will be deleted whenever *either* of these criteria are met. Deletion always happens# from the end of the log.#数据保存时间，默认7天，单位小时log.retention.hours=168# A size-based retention policy for logs. Segments are pruned from the log as long as the remaining# segments don&apos;t drop below log.retention.bytes. Functions independently of log.retention.hours.#log.retention.bytes=1073741824# The maximum size of a log segment file. When this size is reached a new log segment will be created.log.segment.bytes=1073741824# The interval at which log segments are checked to see if they can be deleted according# to the retention policieslog.retention.check.interval.ms=300000############################# Zookeeper ##############################zookeeper地址，多个地址用逗号隔开zookeeper.connect=192.168.43.20:2181,192.168.43.21:2181,192.168.43.22:2181# Timeout in ms for connecting to zookeeperzookeeper.connection.timeout.ms=6000 5.拷贝文件信息到Broker02/Broker03节点上12scp -r /home/hadoop/apps/kafka_2.11-0.10.2.1 hadoop@node04:/home/hadoop/apps/scp -r /home/hadoop/apps/kafka_2.11-0.10.2.1 hadoop@node04:/home/hadoop/apps/ 6.修改Broker02和Broker03信息创建软连接 1[root@hadoop03 kafka_2.11-0.10.2.1]# ln -s /home/hadoop/apps/kafka_2.11-0.10.2.1 /usr/local/kafka 修改配置文件server.properties信息12broker.id=1host.name=192.168.43.23 修改Broker03节点server.properties信息 12broker.id=2host.name=192.168.43.24 7.分别启动Broker01/Broker02/Broker03以后台进程的方式启动Kafka1[root@hadoop03 bin]#./kafka-server-start.sh -daemon config/server.properties 二、Kafka应用实践1.创建主题1234[root@hadoop03 bin]# pwd/usr/local/kafka/bin[root@hadoop03 bin]# ./kafka-topics.sh --create --zookeeper 192.168.43.20:2181 --replication-factor 2 --partitions 3 --topic topicnewtest1Created topic &quot;topicnewtest1&quot;. 2.查看主题12[root@hadoop03 bin]# ./kafka-topics.sh --list --zookeeper 192.168.43.20:2181topicnewtest1 3.查看主题信息12345[root@hadoop03 bin]# ./kafka-topics.sh --describe --zookeeper 192.168.43.20:2181 --topic topicnewtest1Topic:topicnewtest1 PartitionCount:3 ReplicationFactor:2 Configs: Topic: topicnewtest1 Partition: 0 Leader: 2 Replicas: 2,0 Isr: 2,0 Topic: topicnewtest1 Partition: 1 Leader: 0 Replicas: 0,1 Isr: 0,1 Topic: topicnewtest1 Partition: 2 Leader: 1 Replicas: 1,2 Isr: 1,2 4.删除主题123[root@hadoop03 bin]# ./kafka-topics.sh --delete --zookeeper 192.168.43.20:2181 --topic topicnewtest1Topic topicnewtest1 is marked for deletion.Note: This will have no impact if delete.topic.enable is not set to true. 5.增加分区12345678910[root@hadoop03 bin]# ./kafka-topics.sh --alter --zookeeper 192.168.43.20:2181 --topic topicnewtest1 --partitions 5WARNING: If partitions are increased for a topic that has a key, the partition logic or ordering of the messages will be affectedAdding partitions succeeded![root@hadoop03 bin]# ./kafka-topics.sh --describe --zookeeper 192.168.43.20:2181 --topic topicnewtest1Topic:topicnewtest1 PartitionCount:5 ReplicationFactor:2 Configs: Topic: topicnewtest1 Partition: 0 Leader: 1 Replicas: 1,0 Isr: 1,0 Topic: topicnewtest1 Partition: 1 Leader: 2 Replicas: 2,1 Isr: 2,1 Topic: topicnewtest1 Partition: 2 Leader: 0 Replicas: 0,2 Isr: 0,2 Topic: topicnewtest1 Partition: 3 Leader: 1 Replicas: 1,2 Isr: 1,2 Topic: topicnewtest1 Partition: 4 Leader: 2 Replicas: 2,0 Isr: 2,0 6.使用kafka自带的生产者客户端脚本和消费端脚本使用kafka自带的生产者客户端脚本 1[root@hadoop03 bin]# ./kafka-console-producer.sh --broker-list 192.168.43.22:9092,192.168.43.23:9092 --topic topicnewtest1 使用kafka自带的消费者客户端脚本 1[root@hadoop04 bin]# ./kafka-console-consumer.sh --zookeeper 192.168.43.20:2181 --from-beginning --topic topicnewtest1 在生成端发送消息，可以在消费看到消息 7.使用Java访问Kafka产生消息和消费消息 Producer 12345678910111213141516171819202122232425262728293031323334353637383940414243444546package cn.chinahadoop.client;import org.apache.kafka.clients.producer.KafkaProducer;import org.apache.kafka.clients.producer.Producer;import org.apache.kafka.clients.producer.ProducerRecord;import java.util.Date;import java.util.Properties;import java.util.Random;/** * Kafka生产端 * @author Zhangyongliang */public class ProducerClient &#123; public static void main(String[] args)&#123; Properties props = new Properties(); //kafka broker列表 props.put(&quot;bootstrap.servers&quot;, &quot;192.168.43.22:9092,192.168.43.23:9092,192.168.43.24:9092&quot;); //acks=1表示Broker接收到消息成功写入本地log文件后向Producer返回成功接收的信号，不需要等待所有的Follower全部同步完消息后再做回应 props.put(&quot;acks&quot;, &quot;1&quot;); //key和value的字符串序列化类 props.put(&quot;key.serializer&quot;, &quot;org.apache.kafka.common.serialization.StringSerializer&quot;); props.put(&quot;value.serializer&quot;, &quot;org.apache.kafka.common.serialization.StringSerializer&quot;); Producer&lt;String, String&gt; producer = new KafkaProducer&lt;String, String&gt;(props); //用户产生随机数，模拟消息生成 Random rand = new Random(); for(int i = 0; i &lt; 20; i++) &#123; //通过随机数产生一个ip地址作为key发送出去 String ip = &quot;192.168.1.&quot; + rand.nextInt(255); long runtime = new Date().getTime(); //组装一条消息内容 String msg = runtime + &quot;---&quot; + ip; try &#123; Thread.sleep(1000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; System.out.println(&quot;send to kafka-&gt;key:&quot; + ip + &quot; value:&quot; + msg); //向kafka topictest1主题发送消息 producer.send(new ProducerRecord&lt;String, String&gt;(&quot;topicnewtest1&quot;, ip, msg)); &#125; producer.close(); &#125;&#125; ConSumer 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112package com.yongliang.kafka;import org.apache.kafka.clients.consumer.ConsumerRecord;import org.apache.kafka.clients.consumer.ConsumerRecords;import org.apache.kafka.clients.consumer.KafkaConsumer;import java.util.ArrayList;import java.util.Arrays;import java.util.List;import java.util.Properties;/** * Kafka消费端 * @author Zhangyongliang */public class ConsumerClient &#123; /** * 手动提交偏移量 */ public static void manualCommintClient()&#123; Properties props = new Properties(); //kafka broker列表 props.put(&quot;bootstrap.servers&quot;, &quot;192.168.43.22:9092,192.168.43.23:9092,192.168.43.24:9092&quot;); //consumer group id props.put(&quot;group.id&quot;, &quot;yongliang&quot;); //手动提交offset props.put(&quot;enable.auto.commit&quot;, &quot;false&quot;); //earliest表示从最早的偏移量开始拉取，latest表示从最新的偏移量开始拉取，none表示如果没有发现该Consumer组之前拉取的偏移量则抛异常。默认值latest。 props.put(&quot;auto.offset.reset&quot;, &quot;earliest&quot;); //key和value的字符串反序列化类 props.put(&quot;key.deserializer&quot;, &quot;org.apache.kafka.common.serialization.StringDeserializer&quot;); props.put(&quot;value.deserializer&quot;, &quot;org.apache.kafka.common.serialization.StringDeserializer&quot;); KafkaConsumer&lt;String, String&gt; consumer = new KafkaConsumer&lt;String, String&gt;(props); //consumer订阅topictest1主题，同时消费多个主题用逗号隔开 consumer.subscribe(Arrays.asList(&quot;topicnewtest1&quot;)); //每次最少处理10条消息后才提交 final int minBatchSize = 10; //用于保存消息的list List&lt;ConsumerRecord&lt;String, String&gt;&gt; bufferList = new ArrayList&lt;ConsumerRecord&lt;String, String&gt;&gt;(); while (true) &#123; System.out.println(&quot;--------------start pull message---------------&quot; ); long starttime = System.currentTimeMillis(); //poll方法需要传入一个超时时间，当没有可以拉取的消息时先等待， //如果已到超时时间还没有可以拉取的消息则进行下一轮拉取，单位毫秒 ConsumerRecords&lt;String, String&gt; records = consumer.poll(1000); long endtime = System.currentTimeMillis(); long tm = (endtime - starttime) / 1000; System.out.println(&quot;--------------end pull message and times=&quot; + tm + &quot;s -------------&quot;); for (ConsumerRecord&lt;String, String&gt; record : records) &#123; System.out.printf(&quot;partition = %d, offset = %d, key = %s, value = %s%n&quot;, record.partition(), record.offset(), record.key(), record.value()); bufferList.add(record); &#125; System.out.println(&quot;--------------buffer size-&gt;&quot; + bufferList.size()); //如果读取到的消息满了10条, 就进行处理 if (bufferList.size() &gt;= minBatchSize) &#123; System.out.println(&quot;******start deal message******&quot;); try &#123; //当前线程睡眠1秒钟，模拟消息处理过程 Thread.sleep(1000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; System.out.println(&quot;manual commint offset start...&quot;); //处理完之后进行提交 consumer.commitSync(); //清除list, 继续接收 bufferList.clear(); System.out.println(&quot;manual commint offset end...&quot;); &#125; &#125; &#125; /** * 自动提交偏移量 */ public static void autoCommintClient()&#123; Properties props = new Properties(); //kafka broker列表 props.put(&quot;bootstrap.servers&quot;, &quot;192.168.43.22:9092,192.168.43.23:9092,192.168.43.24:9092&quot;); props.put(&quot;group.id&quot;, &quot;newConsumerGroup&quot;); //自动提交 props.put(&quot;enable.auto.commit&quot;, &quot;true&quot;); //自动提交时间间隔1000毫秒 props.put(&quot;auto.commit.interval.ms&quot;, &quot;1000&quot;); //earliest表示从最早的偏移量开始拉取，latest表示从最新的偏移量开始拉取，none表示如果没有发现该Consumer组之前拉取的偏移量则抛异常。默认值latest。 props.put(&quot;auto.offset.reset&quot;, &quot;earliest&quot;); //key和value的字符串反序列化类 props.put(&quot;key.deserializer&quot;, &quot;org.apache.kafka.common.serialization.StringDeserializer&quot;); props.put(&quot;value.deserializer&quot;, &quot;org.apache.kafka.common.serialization.StringDeserializer&quot;); KafkaConsumer&lt;String, String&gt; consumer = new KafkaConsumer&lt;String, String&gt;(props); //consumer订阅topictest1主题，同时消费多个主题用逗号隔开 consumer.subscribe(Arrays.asList(&quot;topicnewtest1&quot;)); while (true) &#123; //poll方法需要传入一个超时时间，当没有可以拉取的消息时先等待， //如果已到超时时间还没有可以拉取的消息则进行下一轮拉取，单位毫秒 ConsumerRecords&lt;String, String&gt; records = consumer.poll(1000); //处理拉取过来的消息 for (ConsumerRecord&lt;String, String&gt; record : records)&#123; System.out.printf(&quot;partition = %d, offset = %d, key = %s, value = %s%n&quot;, record.partition(), record.offset(), record.key(), record.value()); &#125; &#125; &#125; public static void main(String[] args)&#123; //自动提交offset// autoCommintClient(); //手动提交offset manualCommintClient(); &#125;&#125;","tags":[]},{"title":"CentOS 单机搭建FastDFS文件系统","date":"2018-02-01T05:58:09.645Z","path":"2018/02/01/CentOS_单机搭建FastDFS文件系统/","text":"此例为在CentOS7.2 单机上搭建一个FastDFS 文件管理系统 FastDFS架构图 安装所需文件均上传到百度云盘，位置：FastDFS百度云盘安装清单如下：|软件名称|版本|百度云盘存放名称||:—-:|:—-:|:—–:||FastDFS|5.11|fastdfs-5.11.zip||FastDFS-Nginx-module|无|fastdfs-nginx-module-master.zip||LibFastCommon|1.0.36|libfastcommon-1.0.36.zip||nginx|1.10.3|nginx-1.10.3.tar.gz| 一、安装FastDFS1.安装libfastcommon先解压安装包到目录 1[root@localhost fastDFS]# unzip libfastcommon-1.0.36.zip 解压后目录如下：1234567891011[root@localhost fastdfs-5.11]# ll[root@localhost libfastcommon-1.0.36]# ll总用量 32drwxr-xr-x. 2 root root 117 4月 5 2017 doc-rw-r--r--. 1 root root 8005 4月 5 2017 HISTORY-rw-r--r--. 1 root root 566 4月 5 2017 INSTALL-rw-r--r--. 1 root root 1606 4月 5 2017 libfastcommon.spec-rwxr-xr-x. 1 root root 3099 4月 5 2017 make.shdrwxr-xr-x. 2 root root 191 4月 5 2017 php-fastcommon-rw-r--r--. 1 root root 2763 4月 5 2017 READMEdrwxr-xr-x. 3 root root 4096 1月 17 11:21 src 安装C编译工具 gcc 1[root@localhost fastdfs-5.11]# yum -y install gcc-c++ 编译libfastcommon软件并安装 1[root@localhost fastdfs-5.11]# ./make.sh &amp;&amp; ./make.sh install 为libcommon 创建软链接到/usr/local/lib目录下 1234[root@localhost fastdfs-5.11]# ln -s /usr/lib64/libfastcommon.so /usr/local/lib/libfastcommon.so[root@localhost fastdfs-5.11]# ln -s /usr/lib64/libfastcommon.so /usr/lib/libfastcommon.so[root@localhost fastdfs-5.11]# ln -s /usr/lib64/libfdfsclient.so /usr/local/lib/libfdfsclient.so[root@localhost fastdfs-5.11]# ln -s /usr/lib64/libfdfsclient.so /usr/lib/libfdfsclient.so 2.安装FastDFS解压安装包 1[root@localhost fastDFS]# unzip fastdfs-5.11.zip 解压后目录如下：1234567891011121314151617总用量 128drwxr-xr-x. 3 root root 4096 1月 17 11:25 clientdrwxr-xr-x. 2 root root 4096 1月 17 11:25 commondrwxr-xr-x. 2 root root 146 6月 3 2017 conf-rw-r--r--. 1 root root 35067 6月 3 2017 COPYING-3_0.txt-rw-r--r--. 1 root root 3171 6月 3 2017 fastdfs.spec-rw-r--r--. 1 root root 33100 6月 3 2017 HISTORYdrwxr-xr-x. 2 root root 48 6月 3 2017 init.d-rw-r--r--. 1 root root 7755 6月 3 2017 INSTALL-rwxr-xr-x. 1 root root 5548 6月 3 2017 make.shdrwxr-xr-x. 2 root root 4096 6月 3 2017 php_client-rw-r--r--. 1 root root 2380 6月 3 2017 README.md-rwxr-xr-x. 1 root root 1768 6月 3 2017 restart.sh-rwxr-xr-x. 1 root root 1680 6月 3 2017 stop.shdrwxr-xr-x. 4 root root 4096 1月 17 11:25 storagedrwxr-xr-x. 2 root root 4096 6月 3 2017 testdrwxr-xr-x. 2 root root 4096 1月 17 11:25 tracker 进入解压目录并进行编译和安装 12[root@localhost fastDFS]# cd fastdfs-5.11/[root@localhost fastdfs-5.11]# ./make.sh &amp;&amp; ./make.sh install 安装成功后，FastDFS会安装在/etc/fdfs目录下： 123456789101112[root@localhost fastdfs-5.11]# ll /etc/fdfs/总用量 76-rw-r--r--. 1 root root 316 1月 17 11:47 client.conf-rw-r--r--. 1 root root 1461 1月 17 11:25 client.conf.sample-rw-r--r--. 1 root root 955 1月 17 13:20 http.conf-rw-r--r--. 1 root root 31172 1月 17 13:21 mime.types-rw-r--r--. 1 root root 3716 1月 17 12:57 mod_fastdfs.conf-rw-r--r--. 1 root root 1278 1月 17 11:40 storage.conf-rw-r--r--. 1 root root 7927 1月 17 11:25 storage.conf.sample-rw-r--r--. 1 root root 105 1月 17 11:25 storage_ids.conf.sample-rw-r--r--. 1 root root 1356 1月 17 11:34 tracker.conf-rw-r--r--. 1 root root 7389 1月 17 11:25 tracker.conf.sample 我们需要把这三个示例文件复制一份，去掉.sample 123[root@localhost fdfs]# cp client.conf.sample client.conf[root@localhost fdfs]# cp storage.conf.sample storage.conf[root@localhost fdfs]# cp tracker.conf.sample tracker.conf FastDFS安装结束 二、安装Tracker1.创建tracker工作目录此目录用于保存tracker 的data和log 1[root@localhost fdfs]# mkdir /opt/fastdfs_tracker 2.配置tracker配置 /etc/fdfs目录下tracker.conf主要实现以下4个配置内容： 123451.disabled=false 2.port=22122 #默认端口号 3.base_path=/opt/fastdfs_tracker #我刚刚创建的目录 4.http.server_port=8080 #默认端口是80805.bind_addr= 0.0.0.0 监听地址 完整tracker.conf 文件信息如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103disabled=falsebind_addr= 0.0.0.0port=22122connect_timeout=30network_timeout=60base_path=/opt/fastdfs_trackermax_connections=512accept_threads=1work_threads=4min_buff_size = 8KBmax_buff_size = 128KBstore_lookup=2store_group=group2store_server=0store_path=0download_server=0reserved_storage_space = 10%log_level=inforun_by_group=run_by_user=allow_hosts=*sync_log_buff_interval = 10check_active_interval = 120thread_stack_size = 64KBstorage_ip_changed_auto_adjust = truestorage_sync_file_max_delay = 86400storage_sync_file_max_time = 300use_trunk_file = false slot_min_size = 256slot_max_size = 16MBtrunk_file_size = 64MBtrunk_create_file_advance = falsetrunk_create_file_time_base = 02:00trunk_create_file_interval = 86400trunk_create_file_space_threshold = 20Gtrunk_init_check_occupying = falsetrunk_init_reload_from_binlog = falsetrunk_compress_binlog_min_interval = 0use_storage_id = falsestorage_ids_filename = storage_ids.confid_type_in_filename = ipstore_slave_file_use_link = falserotate_error_log = falseerror_log_rotate_time=00:00rotate_error_log_size = 0log_file_keep_days = 0use_connection_pool = falseconnection_pool_max_idle_time = 3600http.server_port=8080http.check_alive_interval=30http.check_alive_type=tcphttp.check_alive_uri=/status.html 修改保存后创建软引用 1[root@localhost fdfs]# ln -s /usr/bin/fdfs_storaged /usr/local/bin 4.启动tracker，并加入开机启动项1[root@localhost fdfs]# service fdfs_trackerd start 进行刚刚创建的tracker目录，发现目录中多了data和log两个目录 1234[root@localhost fdfs]# ll /opt/fastdfs_tracker/总用量 0drwxr-xr-x. 2 root root 178 1月 17 13:48 datadrwxr-xr-x. 2 root root 26 1月 17 11:35 logs 将tracker加入开机启动项 1[root@localhost fdfs]# echo &quot;service fdfs_trackerd start&quot; |tee -a /etc/rc.d/rc.local 查看一下tracker的端口监听情况 12[root@localhost fdfs]# netstat -unltp|grep fdfstcp 0 0 0.0.0.0:22122 0.0.0.0:* LISTEN 3088/fdfs_trackerd 三、安装Storage1.配置storage工作目录由于storage还需要一个目录用来存储数据，因此多建了两个目录fastdfs_storage_data,fastdfs_storage1234567[root@localhost opt]# mkdir fastdfs_storage[root@localhost opt]# mkdir fastdfs_storage_data[root@localhost opt]# ll总用量 0drwxr-xr-x. 4 root root 30 1月 17 11:45 fastdfs_storagedrwxr-xr-x. 3 root root 18 1月 17 11:45 fastdfs_storage_datadrwxr-xr-x. 4 root root 30 1月 17 11:35 fastdfs_tracker 2.配置storage文件修改 /etc/fdfs 目录下 storage.conf 文件修改要点如下： 123456781.disabled=false 2.group_name=group1 #组名，根据实际情况修改 3.port=23000 #设置storage的端口号，默认是23000，同一个组的storage端口号必须一致 4.base_path=/opt/fastdfs_storage #设置storage数据文件和日志目录 5.store_path_count=1 #存储路径个数，需要和store_path个数匹配 6.store_path0=/opt/fastdfs_storage_data #实际文件存储路径 7.tracker_server=192.168.43.60:22122 #我CentOS7的ip地址 8.http.server_port=8888 #设置 http 端口号 完整信息如下： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556disabled=falsegroup_name=group1bind_addr= 0.0.0.0client_bind=trueport=23000connect_timeout=30network_timeout=60heart_beat_interval=30stat_report_interval=60base_path=/opt/fastdfs_storagemax_connections=256buff_size = 256KBaccept_threads=1work_threads=4disk_rw_separated = truedisk_reader_threads = 1disk_writer_threads = 1sync_wait_msec=50sync_interval=0sync_start_time=00:00sync_end_time=23:59write_mark_file_freq=500store_path_count=1store_path0=/opt/fastdfs_storage_datasubdir_count_per_path=256tracker_server=192.168.43.60:22122log_level=inforun_by_group=run_by_user=allow_hosts=*file_distribute_path_mode=0file_distribute_rotate_count=100fsync_after_written_bytes=0sync_log_buff_interval=10sync_binlog_buff_interval=10sync_stat_file_interval=300thread_stack_size=512KBupload_priority=10if_alias_prefix=check_file_duplicate=0file_signature_method=hashkey_namespace=FastDFSkeep_alive=0use_access_log = falserotate_access_log = falseaccess_log_rotate_time=00:00rotate_error_log = falseerror_log_rotate_time=00:00rotate_access_log_size = 0rotate_error_log_size = 0log_file_keep_days = 0file_sync_skip_invalid_record=falseuse_connection_pool = falseconnection_pool_max_idle_time = 3600http.domain_name=http.server_port=8888 修改保存后创建软引用1[root@localhost fdfs]# ln -s /usr/bin/fdfs_storaged /usr/local/bin 3.启动Storage1[root@localhost fdfs]# service fdfs_storaged start 设置开机启动： 1[root@localhost fdfs]# echo &quot;service fdfs_storaged start&quot; |tee -a /etc/rc.d/rc.local 查看一下服务是否启动 123[root@localhost fdfs]# netstat -unltp | grep fdfs tcp 0 0 0.0.0.0:22122 0.0.0.0:* LISTEN 3088/fdfs_trackerd tcp 0 0 0.0.0.0:23000 0.0.0.0:* LISTEN 3139/fdfs_storaged 4.校验整合到这里，fastdfs的东西都已安装完成，最后我们还要确定一下，storage是否注册到了tracker中去。查看命令： 1[root@localhost fdfs]# /usr/bin/fdfs_monitor /etc/fdfs/storage.conf 成功后可以看到：ip_addr = 192.168.43.60 (localhost.localdomain) ACTIVE 四、测试1.配置客户端修改 /etc/fdfs/目录下的client.conf 文件修改要点为： 123base_path=/opt/fastdfs_tracker #tracker服务器文件路径tracker_server=192.168.43.60:22122 #tracker服务器IP地址和端口号http.tracker_server_port=8080 # tracker 服务器的 http端口号，必须和tracker的设置对应起来 完整client.conf 文件信息如下： 1234567891011connect_timeout=30network_timeout=60base_path=/opt/fastdfs_trackertracker_server=192.168.43.60:22122log_level=infouse_connection_pool = falseconnection_pool_max_idle_time = 3600load_fdfs_parameters_from_tracker=falseuse_storage_id = falsestorage_ids_filename = storage_ids.confhttp.tracker_server_port=8080 模拟上传从个人用户目录上传一个图片，进行测试 1[root@localhost fdfs]# fdfs_upload_file /etc/fdfs/client.conf /home/zhangyongliang/9408.jpg #这后面放的是图片的位置 成功后会返回图片存储路径 12[root@localhost fdfs]# fdfs_upload_file /etc/fdfs/client.conf /home/zhangyongliang/9408.jpg group1/M00/00/00/wKgrPFpe9OqAWsHxAAH5yvc2jn8251.jpg 组名：group1磁盘：M00目录：00/00文件名称：wKgrPFpe9OqAWsHxAAH5yvc2jn8251.jpg定位上传的文件位置如下： 1234[root@localhost fdfs]# ll /opt/fastdfs_storage_data/data/00/00/总用量 256-rw-r--r--. 1 root root 129482 1月 17 15:02 wKgrPFpe9OqAWsHxAAH5yvc2jn8251.jpg-rw-r--r--. 1 root root 129482 1月 17 11:53 wKgrPFpeyM2ATkGUAAH5yvc2jn8013.jpg 实际文件存储路径下有创建好的多级目录。data下有256个1级目录，每级目录下又有256个2级子目录，总共65536个文件，新写的文件会以hash的方式被路由到其中某个子目录下，然后将文件数据直接作为一个本地文件存储到该目录中。如果要访问刚上传的图片，我们得需要结合nginx来实现 五、安装Nginx并实现配置1.安装Nginx依赖环境123[root@localhost fdfs]# yum -y install pcre pcre-devel [root@localhost fdfs]# yum -y install zlib zlib-devel [root@localhost fdfs]# yum -y install openssl openssl-devel 2.安装nginx并添加fastdfs-nginx-module解压nginx和fastdfs-nginx-module 12[root@localhost fdfs]# tar -zxvf nginx-1.10.3.tar.gz[root@localhost fdfs]# unzip fastdfs-nginx-module-master.zip 解压后进入nginx目录编译安装nginx,并添加fastdfs-nginx-module 1[root@localhost nginx-1.10.3]# ./configure --prefix=/usr/local/nginx --add-module=/home/zhangyongliang/apps/fastdfs-nginx-module-master/src #解压后fastdfs-nginx-module所在的位置 之后进行编译和安装 1[root@localhost nginx-1.10.3]# make &amp;&amp; make isntall 安装成功后，nginx会安装在/usr/local/nginx,安装后查看 123456789101112[root@localhost src]# ll /usr/local/nginx/总用量 8drwx------. 2 nobody root 6 1月 17 13:23 client_body_tempdrwxr-xr-x. 2 root root 4096 1月 17 13:17 confdrwx------. 2 nobody root 6 1月 17 13:23 fastcgi_tempdrwxr-xr-x. 2 root root 40 1月 17 13:17 htmldrwxr-xr-x. 2 root root 58 1月 17 13:49 logs-rw-r--r--. 1 root root 1156 1月 17 13:29 nginx.confdrwx------. 2 nobody root 6 1月 17 13:23 proxy_tempdrwxr-xr-x. 2 root root 19 1月 17 13:17 sbindrwx------. 2 nobody root 6 1月 17 13:23 scgi_tempdrwx------. 2 nobody root 6 1月 17 13:23 uwsgi_temp 安装成功后，nginx尚未运行时，nginx文件夹没有临时文件夹，例如fastcgi_temp这些文件。 3.配置Storage Nginx修改Nginx 目录下 conf 的配置文件nginx.conf,新增location信息，具体如下： 123456789101112131415161718server &#123; listen 9991; server_name localhost; location / &#123; root html; index index.html index.htm; &#125; location ~/group1/M00 &#123; root /opt/fastdfs_storage/data; ngx_fastdfs_module; &#125; location = /50x.html &#123; root html; &#125;&#125; 然后进入FastDFS安装时的解压过的目录，将http.conf和mime.types拷贝到/etc/fdfs目录下：12[root@localhost src]# cp http.conf mime.types /etc/fdfs/[root@localhost src]# cp mime.types /etc/fdfs/ 另外还需要把fastdfs-nginx-module安装目录中src目录下的mod_fastdfs.conf也拷贝到/etc/fdfs目录下： 1[root@localhost src]# cp mod_fastdfs.conf /etc/fdfs/ 对刚刚拷贝的mod_fastdfs.conf文件进行修改： 123456base_path=/opt/fastdfs_storage #保存日志目录tracker_server=192.168.43.60:22122 #tracker服务器的IP地址以及端口号storage_server_port=23000 #storage服务器的端口号url_have_group_name = true #文件 url 中是否有 group 名store_path0=/opt/fastdfs_storage_data #存储路径group_count = 1 #设置组的个数 在文件的最后，设置group12345[group1]group_name=group1storage_server_port=23000store_path_count=1store_path0=/opt/fastdfs_storage_data 创建M00至storage存储目录的符号连接： 1ln -s /opt/fastdfs_storage_data/data/ /opt/fastdfs_storage_data/data/M00 启动Nginx： 1[root@localhost src]# /usr/local/nginx/sbin/nginx 访问Nginx是否启动 1234567891011121314151617181920212223242526[root@localhost src]# curl localhost:9991&lt;!DOCTYPE html&gt;&lt;html&gt;&lt;head&gt;&lt;title&gt;Welcome to nginx!&lt;/title&gt;&lt;style&gt; body &#123; width: 35em; margin: 0 auto; font-family: Tahoma, Verdana, Arial, sans-serif; &#125;&lt;/style&gt;&lt;/head&gt;&lt;body&gt;&lt;h1&gt;Welcome to nginx!&lt;/h1&gt;&lt;p&gt;If you see this page, the nginx web server is successfully installed andworking. Further configuration is required.&lt;/p&gt;&lt;p&gt;For online documentation and support please refer to&lt;a href=&quot;http://nginx.org/&quot;&gt;nginx.org&lt;/a&gt;.&lt;br/&gt;Commercial support is available at&lt;a href=&quot;http://nginx.com/&quot;&gt;nginx.com&lt;/a&gt;.&lt;/p&gt;&lt;p&gt;&lt;em&gt;Thank you for using nginx.&lt;/em&gt;&lt;/p&gt;&lt;/body&gt;&lt;/html&gt; 4.配置Tracker Nginx在nginx.conf 文件添加一个虚拟机 1234567891011121314upstream fdfs_group1 &#123; server 127.0.0.1:9991; &#125; server &#123; listen 80; server_name localhost; location /group1/M00 &#123; proxy_pass http://fdfs_group1; &#125; error_page 500 502 503 504 /50x.html; location = /50x.html &#123; root html; &#125; &#125; 完整nginx.conf配置文件如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133#user nobody;worker_processes 1;#error_log logs/error.log;#error_log logs/error.log notice;#error_log logs/error.log info;#pid logs/nginx.pid;events &#123; worker_connections 1024;&#125;http &#123; include mime.types; default_type application/octet-stream; #log_format main &apos;$remote_addr - $remote_user [$time_local] &quot;$request&quot; &apos; # &apos;$status $body_bytes_sent &quot;$http_referer&quot; &apos; # &apos;&quot;$http_user_agent&quot; &quot;$http_x_forwarded_for&quot;&apos;; #access_log logs/access.log main; sendfile on; #tcp_nopush on; #keepalive_timeout 0; keepalive_timeout 65; #gzip on; server &#123; listen 9991; server_name localhost; #charset koi8-r; #access_log logs/host.access.log main; location / &#123; root html; index index.html index.htm; &#125; location ~/group1/M00 &#123; root /opt/fastdfs_storage/data; ngx_fastdfs_module; &#125; #error_page 404 /404.html; # redirect server error pages to the static page /50x.html # error_page 500 502 503 504 /50x.html; location = /50x.html &#123; root html; &#125; # proxy the PHP scripts to Apache listening on 127.0.0.1:80 # #location ~ \\.php$ &#123; # proxy_pass http://127.0.0.1; #&#125; # pass the PHP scripts to FastCGI server listening on 127.0.0.1:9000 # #location ~ \\.php$ &#123; # root html; # fastcgi_pass 127.0.0.1:9000; # fastcgi_index index.php; # fastcgi_param SCRIPT_FILENAME /scripts$fastcgi_script_name; # include fastcgi_params; #&#125; # deny access to .htaccess files, if Apache&apos;s document root # concurs with nginx&apos;s one # #location ~ /\\.ht &#123; # deny all; #&#125; &#125; upstream fdfs_group1 &#123; server 127.0.0.1:9991; &#125; server &#123; listen 80; server_name localhost; location /group1/M00 &#123; proxy_pass http://fdfs_group1; &#125; error_page 500 502 503 504 /50x.html; location = /50x.html &#123; root html; &#125; &#125; # another virtual host using mix of IP-, name-, and port-based configuration # #server &#123; # listen 8000; # listen somename:8080; # server_name somename alias another.alias; # location / &#123; # root html; # index index.html index.htm; # &#125; #&#125; # HTTPS server # #server &#123; # listen 443 ssl; # server_name localhost; # ssl_certificate cert.pem; # ssl_certificate_key cert.key; # ssl_session_cache shared:SSL:1m; # ssl_session_timeout 5m; # ssl_ciphers HIGH:!aNULL:!MD5; # ssl_prefer_server_ciphers on; # location / &#123; # root html; # index index.html index.htm; # &#125; #&#125;&#125; 将Nginx重新启动 1[root@localhost src]# /usr/local/nginx/sbin/nginx -s reload 访问Nginx是否已经启动 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152[root@localhost src]# curl localhost:9991&lt;!DOCTYPE html&gt;&lt;html&gt;&lt;head&gt;&lt;title&gt;Welcome to nginx!&lt;/title&gt;&lt;style&gt; body &#123; width: 35em; margin: 0 auto; font-family: Tahoma, Verdana, Arial, sans-serif; &#125;&lt;/style&gt;&lt;/head&gt;&lt;body&gt;&lt;h1&gt;Welcome to nginx!&lt;/h1&gt;&lt;p&gt;If you see this page, the nginx web server is successfully installed andworking. Further configuration is required.&lt;/p&gt;&lt;p&gt;For online documentation and support please refer to&lt;a href=&quot;http://nginx.org/&quot;&gt;nginx.org&lt;/a&gt;.&lt;br/&gt;Commercial support is available at&lt;a href=&quot;http://nginx.com/&quot;&gt;nginx.com&lt;/a&gt;.&lt;/p&gt;&lt;p&gt;&lt;em&gt;Thank you for using nginx.&lt;/em&gt;&lt;/p&gt;&lt;/body&gt;&lt;/html&gt;[root@localhost src]# curl localhost&lt;!DOCTYPE html&gt;&lt;html&gt;&lt;head&gt;&lt;title&gt;Welcome to nginx!&lt;/title&gt;&lt;style&gt; body &#123; width: 35em; margin: 0 auto; font-family: Tahoma, Verdana, Arial, sans-serif; &#125;&lt;/style&gt;&lt;/head&gt;&lt;body&gt;&lt;h1&gt;Welcome to nginx!&lt;/h1&gt;&lt;p&gt;If you see this page, the nginx web server is successfully installed andworking. Further configuration is required.&lt;/p&gt;&lt;p&gt;For online documentation and support please refer to&lt;a href=&quot;http://nginx.org/&quot;&gt;nginx.org&lt;/a&gt;.&lt;br/&gt;Commercial support is available at&lt;a href=&quot;http://nginx.com/&quot;&gt;nginx.com&lt;/a&gt;.&lt;/p&gt;&lt;p&gt;&lt;em&gt;Thank you for using nginx.&lt;/em&gt;&lt;/p&gt;&lt;/body&gt;&lt;/html&gt; 5.HTTP访问图片资源 访问图片资源路径http://192.168.43.60/group1/M00/00/00/wKgrPFpeyM2ATkGUAAH5yvc2jn8013.jpg FastDFS资源访问截图 可以看到已上传的图片，说明你已成功实现了FastDFS单机的文件系统搭建。 补充说明：如果Tracker 服务、Storage服务、Nginx服务开机后没有自启动，请执行一下操作并进行重启 12[root@localhost ~]# chkconfig --add fdfs_trackerd[root@localhost ~]# chkconfig --add fdfs_storaged 编辑目录下的/etc/rc.d/rc.local,内容如下：1234567891011121314#!/bin/bash# THIS FILE IS ADDED FOR COMPATIBILITY PURPOSES## It is highly advisable to create own systemd services or udev rules# to run scripts during boot instead of using this file.## In contrast to previous versions due to parallel execution during boot# this script will NOT be run after all other services.## Please note that you must run &apos;chmod +x /etc/rc.d/rc.local&apos; to ensure# that this script will be executed during boot.touch /var/lock/subsys/local/usr/local/nginx/sbin/nginx 主要增加了Nginx的启动，之后进行文件生效，重新启动系统 123[root@localhost ~]# chmod +x /etc/rc.d/rc.local[root@localhost ~]# source /etc/rc.d/rc.local [root@localhost ~]# reboot","tags":[]},{"title":"CentOS 7.2搭建FastDFS 分布式文件系统，实现高可用集群","date":"2018-02-01T05:57:24.762Z","path":"2018/02/01/CentOS_7.2搭建FastDFS_分布式文件系统，实现高可用集群/","text":"分布式集群搭建结构 双Tracker 2组Group 轮询存储策略 Keepalived+Nginx高可用 Nginx缓存 4个存储节点 一、 集群规划清单1.安装清单 软件名称 版本 百度云盘存放名称 FastDFS 5.11 fastdfs-5.11.zip FastDFS-Nginx-module 无 fastdfs-nginx-module-master.zip LibFastCommon 1.0.36 libfastcommon-1.0.36.zip nginx 1.10.3 nginx-1.10.3.tar.gz nginx-pure-cache 2.3 ngx_cache_purge-2.3.tar.gz 安装所需文件均上传到百度云盘，位置：FastDFS百度云盘 2.集群规划 虚拟机 IP 说明 Keepalived+Nginx1[Master] 192.168.43.101 Nginx Server 01 Keeepalived+Nginx[Backup] 192.168.43.102 Nginx Server 02 VIP 192.168.43.150 虚拟漂移IP Tracker01 192.168.43.70 Tracker01服务器 Tracker02 192.168.43.71 Tracker02服务器 Storage01 192.168.43.72 Storage01服务器【group1】 Storage02 192.168.43.73 Storage02服务器【group1】 Storage03 192.168.43.74 Storage03服务器【group2】 Storage04 192.168.43.75 Storage04服务器【group2】 整体架构图如下图所示： 图片来源：CSDN作者 liuyazhuang 二、集群安装以下操作均在关闭所有节点防火墙进行的，请根据个人情况开启相关端口或关闭防火墙 1.安装LibFastCommon/FastDFS模块执行节点 Tracker01、Tracker02、Storage01、Storage03、Storage041[root@localhost fastDFS]# unzip libfastcommon-1.0.36.zip 解压后目录如下：1234567891011[root@localhost fastdfs-5.11]# ll[root@localhost libfastcommon-1.0.36]# ll总用量 32drwxr-xr-x. 2 root root 117 4月 5 2017 doc-rw-r--r--. 1 root root 8005 4月 5 2017 HISTORY-rw-r--r--. 1 root root 566 4月 5 2017 INSTALL-rw-r--r--. 1 root root 1606 4月 5 2017 libfastcommon.spec-rwxr-xr-x. 1 root root 3099 4月 5 2017 make.shdrwxr-xr-x. 2 root root 191 4月 5 2017 php-fastcommon-rw-r--r--. 1 root root 2763 4月 5 2017 READMEdrwxr-xr-x. 3 root root 4096 1月 17 11:21 src 安装C编译工具 gcc 1[root@localhost fastdfs-5.11]# yum -y install gcc-c++ 安装装LibFastCommon 编译libfastcommon软件并安装 1[root@localhost fastdfs-5.11]# ./make.sh &amp;&amp; ./make.sh install 为libcommon 创建软链接到/usr/local/lib目录下 1234[root@localhost fastdfs-5.11]# ln -s /usr/lib64/libfastcommon.so /usr/local/lib/libfastcommon.so[root@localhost fastdfs-5.11]# ln -s /usr/lib64/libfastcommon.so /usr/lib/libfastcommon.so[root@localhost fastdfs-5.11]# ln -s /usr/lib64/libfdfsclient.so /usr/local/lib/libfdfsclient.so[root@localhost fastdfs-5.11]# ln -s /usr/lib64/libfdfsclient.so /usr/lib/libfdfsclient.so 安装FastDFS解压安装包1[root@localhost fastDFS]# unzip fastdfs-5.11.zip 进入解压目录并进行编译和安装 12[root@localhost fastDFS]# cd fastdfs-5.11/[root@localhost fastdfs-5.11]# ./make.sh &amp;&amp; ./make.sh install 安装成功后，FastDFS会安装在/etc/fdfs目录下： 123456789101112[root@localhost fastdfs-5.11]# ll /etc/fdfs/总用量 76-rw-r--r--. 1 root root 316 1月 17 11:47 client.conf-rw-r--r--. 1 root root 1461 1月 17 11:25 client.conf.sample-rw-r--r--. 1 root root 955 1月 17 13:20 http.conf-rw-r--r--. 1 root root 31172 1月 17 13:21 mime.types-rw-r--r--. 1 root root 3716 1月 17 12:57 mod_fastdfs.conf-rw-r--r--. 1 root root 1278 1月 17 11:40 storage.conf-rw-r--r--. 1 root root 7927 1月 17 11:25 storage.conf.sample-rw-r--r--. 1 root root 105 1月 17 11:25 storage_ids.conf.sample-rw-r--r--. 1 root root 1356 1月 17 11:34 tracker.conf-rw-r--r--. 1 root root 7389 1月 17 11:25 tracker.conf.sample 我们需要把这三个示例文件复制一份，去掉.sample 123[root@localhost fdfs]# cp client.conf.sample client.conf[root@localhost fdfs]# cp storage.conf.sample storage.conf[root@localhost fdfs]# cp tracker.conf.sample tracker.conf FastDFS安装结束 2.安装Tracker并实现节点信息配置执行节点 Tracker01、Tracker02 创建tracker工作目录 此目录用于保存tracker 的data和log 1[root@localhost fdfs]# mkdir /opt/fastdfs_tracker 配置tracker 配置 /etc/fdfs目录下tracker.conf主要实现以下5个配置内容： 123451.disabled=false 2.port=22122 #默认端口号 3.base_path=/opt/fastdfs_tracker #我刚刚创建的目录 4.http.server_port=8080 #默认端口是80805.store_lookup=0 #采用轮询策略进行存储，0 轮询 1：始终定向到某个group 2：负载进行存储文件 完整tracker.conf 文件信息如下：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103disabled=falsebind_addr= 0.0.0.0port=22122connect_timeout=30network_timeout=60base_path=/opt/fastdfs_trackermax_connections=512accept_threads=1work_threads=4min_buff_size = 8KBmax_buff_size = 128KBstore_lookup=0store_group=group2store_server=0store_path=0download_server=0reserved_storage_space = 10%log_level=inforun_by_group=run_by_user=allow_hosts=*sync_log_buff_interval = 10check_active_interval = 120thread_stack_size = 64KBstorage_ip_changed_auto_adjust = truestorage_sync_file_max_delay = 86400storage_sync_file_max_time = 300use_trunk_file = false slot_min_size = 256slot_max_size = 16MBtrunk_file_size = 64MBtrunk_create_file_advance = falsetrunk_create_file_time_base = 02:00trunk_create_file_interval = 86400trunk_create_file_space_threshold = 20Gtrunk_init_check_occupying = falsetrunk_init_reload_from_binlog = falsetrunk_compress_binlog_min_interval = 0use_storage_id = falsestorage_ids_filename = storage_ids.confid_type_in_filename = ipstore_slave_file_use_link = falserotate_error_log = falseerror_log_rotate_time=00:00rotate_error_log_size = 0log_file_keep_days = 0use_connection_pool = falseconnection_pool_max_idle_time = 3600http.server_port=8080http.check_alive_interval=30http.check_alive_type=tcphttp.check_alive_uri=/status.html 修改保存后创建软引用 1[root@localhost fdfs]# ln -s /usr/bin/fdfs_storaged /usr/local/bin 启动tracker，并加入开机启动项 1[root@localhost fdfs]# service fdfs_trackerd start 将tracker加入开机启动项 1[root@localhost fdfs]# echo &quot;service fdfs_trackerd start&quot; |tee -a /etc/rc.d/rc.local 3.安装Storage模块并实现配置执行节点 Storage01、Storage02、Storage03、Storage04 建立存储目录 在存储各节点建了两个目录fastdfs_storage_data,fastdfs_storage 1234567[root@localhost opt]# mkdir fastdfs_storage[root@localhost opt]# mkdir fastdfs_storage_data[root@localhost opt]# ll总用量 0drwxr-xr-x. 4 root root 30 1月 17 11:45 fastdfs_storagedrwxr-xr-x. 3 root root 18 1月 17 11:45 fastdfs_storage_datadrwxr-xr-x. 4 root root 30 1月 17 11:35 fastdfs_tracker 修改存储节点目录下/etc/fdfs/storage.conf配置信息，具体如下： 123456789disabled=false #启用配置文件 group_name=group1 #组名（第一组为 group1， 第二组为 group2） port=23000 #storage 的端口号,同一个组的 storage 端口号必须相同 base_path=/opt/fastdfs_storage #设置storage数据文件和日志目录 store_path0=/opt/fastdfs_storage_data #实际文件存储路径 store_path_count=1 #存储路径个数，需要和 store_path 个数匹配 tracker_server=192.168.43.70:22122 #tracker 服务器的 IP 地址和端口 tracker_server=192.168.43.70:22122 #多个 tracker 直接添加多条配置 http.server_port=8888 #设置 http 端口号 完整配置信息如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657disabled=falsegroup_name=group1bind_addr=client_bind=trueport=23000connect_timeout=30network_timeout=60heart_beat_interval=30stat_report_interval=60base_path=/opt/fastdfs_storagemax_connections=256buff_size = 256KBaccept_threads=1work_threads=4disk_rw_separated = truedisk_reader_threads = 1disk_writer_threads = 1sync_wait_msec=50sync_interval=0sync_start_time=00:00sync_end_time=23:59write_mark_file_freq=500store_path_count=1store_path0=/opt/fastdfs_storage_datasubdir_count_per_path=256tracker_server=192.168.43.70:22122tracker_server=192.168.43.71:22122log_level=inforun_by_group=run_by_user=allow_hosts=*file_distribute_path_mode=0file_distribute_rotate_count=100fsync_after_written_bytes=0sync_log_buff_interval=10sync_binlog_buff_interval=10sync_stat_file_interval=300thread_stack_size=512KBupload_priority=10if_alias_prefix=check_file_duplicate=0file_signature_method=hashkey_namespace=FastDFSkeep_alive=0use_access_log = falserotate_access_log = falseaccess_log_rotate_time=00:00rotate_error_log = falseerror_log_rotate_time=00:00rotate_access_log_size = 0rotate_error_log_size = 0log_file_keep_days = 0file_sync_skip_invalid_record=falseuse_connection_pool = falseconnection_pool_max_idle_time = 3600http.domain_name=http.server_port=8888 启动Storage各节点配置好信息好之后，启动Storage 1[root@localhost fdfs]# service fdfs_storaged start 启动后查看日志情况 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286[root@localhost fdfs]# fdfs_monitor /etc/fdfs/storage.conf[2018-01-20 16:56:48] DEBUG - base_path=/opt/fastdfs_storage, connect_timeout=30, network_timeout=60, tracker_server_count=2, anti_steal_token=0, anti_steal_secret_key length=0, use_connection_pool=0, g_connection_pool_max_idle_time=3600s, use_storage_id=0, storage server id count: 0server_count=2, server_index=0tracker server is 192.168.43.70:22122group count: 2Group 1:group name = group1disk total space = 47073 MBdisk free space = 35162 MBtrunk free space = 0 MBstorage server count = 2active server count = 2storage server port = 23000storage HTTP port = 8888store path count = 1subdir count per path = 256current write server index = 0current trunk file id = 0 Storage 1: id = 192.168.43.72 ip_addr = 192.168.43.72 (localhost.localdomain) ACTIVE http domain = version = 5.11 join time = 2018-01-19 13:59:30 up time = 2018-01-20 12:37:18 total storage = 47073 MB free storage = 35162 MB upload priority = 10 store_path_count = 1 subdir_count_per_path = 256 storage_port = 23000 storage_http_port = 8888 current_write_path = 0 source storage id = if_trunk_server = 0 connection.alloc_count = 256 connection.current_count = 1 connection.max_count = 1 total_upload_count = 3 success_upload_count = 3 total_append_count = 0 success_append_count = 0 total_modify_count = 0 success_modify_count = 0 total_truncate_count = 0 success_truncate_count = 0 total_set_meta_count = 0 success_set_meta_count = 0 total_delete_count = 0 success_delete_count = 0 total_download_count = 0 success_download_count = 0 total_get_meta_count = 0 success_get_meta_count = 0 total_create_link_count = 0 success_create_link_count = 0 total_delete_link_count = 0 success_delete_link_count = 0 total_upload_bytes = 791904 success_upload_bytes = 791904 total_append_bytes = 0 success_append_bytes = 0 total_modify_bytes = 0 success_modify_bytes = 0 stotal_download_bytes = 0 success_download_bytes = 0 total_sync_in_bytes = 775234 success_sync_in_bytes = 775234 total_sync_out_bytes = 0 success_sync_out_bytes = 0 total_file_open_count = 4 success_file_open_count = 4 total_file_read_count = 0 success_file_read_count = 0 total_file_write_count = 8 success_file_write_count = 8 last_heart_beat_time = 2018-01-20 16:56:18 last_source_update = 2018-01-19 19:34:55 last_sync_update = 2018-01-19 15:28:56 last_synced_timestamp = 2018-01-19 15:28:48 (0s delay) Storage 2: id = 192.168.43.73 ip_addr = 192.168.43.73 ACTIVE http domain = version = 5.11 join time = 2018-01-19 14:00:21 up time = 2018-01-20 12:37:42 total storage = 47073 MB free storage = 35166 MB upload priority = 10 store_path_count = 1 subdir_count_per_path = 256 storage_port = 23000 storage_http_port = 8888 current_write_path = 0 source storage id = 192.168.43.72 if_trunk_server = 0 connection.alloc_count = 256 connection.current_count = 1 connection.max_count = 1 total_upload_count = 1 success_upload_count = 1 total_append_count = 0 success_append_count = 0 total_modify_count = 0 success_modify_count = 0 total_truncate_count = 0 success_truncate_count = 0 total_set_meta_count = 0 success_set_meta_count = 0 total_delete_count = 0 success_delete_count = 0 total_download_count = 0 success_download_count = 0 total_get_meta_count = 0 success_get_meta_count = 0 total_create_link_count = 0 success_create_link_count = 0 total_delete_link_count = 0 success_delete_link_count = 0 total_upload_bytes = 775234 success_upload_bytes = 775234 total_append_bytes = 0 success_append_bytes = 0 total_modify_bytes = 0 success_modify_bytes = 0 stotal_download_bytes = 0 success_download_bytes = 0 total_sync_in_bytes = 791904 success_sync_in_bytes = 791904 total_sync_out_bytes = 0 success_sync_out_bytes = 0 total_file_open_count = 4 success_file_open_count = 4 total_file_read_count = 0 success_file_read_count = 0 total_file_write_count = 8 success_file_write_count = 8 last_heart_beat_time = 2018-01-20 16:56:42 last_source_update = 2018-01-19 15:28:48 last_sync_update = 2018-01-19 19:34:59 last_synced_timestamp = 2018-01-19 19:34:55 (0s delay)Group 2:group name = group2disk total space = 47073 MBdisk free space = 35165 MBtrunk free space = 0 MBstorage server count = 2active server count = 2storage server port = 23000storage HTTP port = 8888store path count = 1subdir count per path = 256current write server index = 0current trunk file id = 0 Storage 1: id = 192.168.43.74 ip_addr = 192.168.43.74 ACTIVE http domain = version = 5.11 join time = 2018-01-19 14:01:05 up time = 2018-01-20 12:38:00 total storage = 47073 MB free storage = 35165 MB upload priority = 10 store_path_count = 1 subdir_count_per_path = 256 storage_port = 23000 storage_http_port = 8888 current_write_path = 0 source storage id = if_trunk_server = 0 connection.alloc_count = 256 connection.current_count = 1 connection.max_count = 1 total_upload_count = 4 success_upload_count = 4 total_append_count = 0 success_append_count = 0 total_modify_count = 0 success_modify_count = 0 total_truncate_count = 0 success_truncate_count = 0 total_set_meta_count = 0 success_set_meta_count = 0 total_delete_count = 0 success_delete_count = 0 total_download_count = 0 success_download_count = 0 total_get_meta_count = 0 success_get_meta_count = 0 total_create_link_count = 0 success_create_link_count = 0 total_delete_link_count = 0 success_delete_link_count = 0 total_upload_bytes = 2107770 success_upload_bytes = 2107770 total_append_bytes = 0 success_append_bytes = 0 total_modify_bytes = 0 success_modify_bytes = 0 stotal_download_bytes = 0 success_download_bytes = 0 total_sync_in_bytes = 1550468 success_sync_in_bytes = 1550468 total_sync_out_bytes = 0 success_sync_out_bytes = 0 total_file_open_count = 6 success_file_open_count = 6 total_file_read_count = 0 success_file_read_count = 0 total_file_write_count = 15 success_file_write_count = 15 last_heart_beat_time = 2018-01-20 16:56:38 last_source_update = 2018-01-19 19:35:40 last_sync_update = 2018-01-19 15:28:53 last_synced_timestamp = 2018-01-19 15:28:50 (-1s delay) Storage 2: id = 192.168.43.75 ip_addr = 192.168.43.75 ACTIVE http domain = version = 5.11 join time = 2018-01-19 14:01:27 up time = 2018-01-20 12:38:20 total storage = 47073 MB free storage = 35165 MB upload priority = 10 store_path_count = 1 subdir_count_per_path = 256 storage_port = 23000 storage_http_port = 8888 current_write_path = 0 source storage id = 192.168.43.74 if_trunk_server = 0 connection.alloc_count = 256 connection.current_count = 1 connection.max_count = 1 total_upload_count = 2 success_upload_count = 2 total_append_count = 0 success_append_count = 0 total_modify_count = 0 success_modify_count = 0 total_truncate_count = 0 success_truncate_count = 0 total_set_meta_count = 0 success_set_meta_count = 0 total_delete_count = 0 success_delete_count = 0 total_download_count = 0 success_download_count = 0 total_get_meta_count = 0 success_get_meta_count = 0 total_create_link_count = 0 success_create_link_count = 0 total_delete_link_count = 0 success_delete_link_count = 0 total_upload_bytes = 1550468 success_upload_bytes = 1550468 total_append_bytes = 0 success_append_bytes = 0 total_modify_bytes = 0 success_modify_bytes = 0 stotal_download_bytes = 0 success_download_bytes = 0 total_sync_in_bytes = 2107770 success_sync_in_bytes = 2107770 total_sync_out_bytes = 0 success_sync_out_bytes = 0 total_file_open_count = 6 success_file_open_count = 6 total_file_read_count = 0 success_file_read_count = 0 total_file_write_count = 15 success_file_write_count = 15 last_heart_beat_time = 2018-01-20 16:56:23 last_source_update = 2018-01-19 15:28:49 last_sync_update = 2018-01-19 19:35:46 last_synced_timestamp = 2018-01-19 19:35:40 (0s delay) 如果看到有2组Storage信息，则表示配置信息配置成功，并注册到Tracker中，查看日志启动情况 1234567891011[root@localhost fdfs]# tail -f /opt/fastdfs_storage/logs/storaged.log [2018-01-20 12:37:18] INFO - FastDFS v5.11, base_path=/opt/fastdfs_storage, store_path_count=1, subdir_count_per_path=256, group_name=group1, run_by_group=, run_by_user=, connect_timeout=30s, network_timeout=60s, port=23000, bind_addr=, client_bind=1, max_connections=256, accept_threads=1, work_threads=4, disk_rw_separated=1, disk_reader_threads=1, disk_writer_threads=1, buff_size=256KB, heart_beat_interval=30s, stat_report_interval=60s, tracker_server_count=2, sync_wait_msec=50ms, sync_interval=0ms, sync_start_time=00:00, sync_end_time=23:59, write_mark_file_freq=500, allow_ip_count=-1, file_distribute_path_mode=0, file_distribute_rotate_count=100, fsync_after_written_bytes=0, sync_log_buff_interval=10s, sync_binlog_buff_interval=10s, sync_stat_file_interval=300s, thread_stack_size=512 KB, upload_priority=10, if_alias_prefix=, check_file_duplicate=0, file_signature_method=hash, FDHT group count=0, FDHT server count=0, FDHT key_namespace=, FDHT keep_alive=0, HTTP server port=8888, domain name=, use_access_log=0, rotate_access_log=0, access_log_rotate_time=00:00, rotate_error_log=0, error_log_rotate_time=00:00, rotate_access_log_size=0, rotate_error_log_size=0, log_file_keep_days=0, file_sync_skip_invalid_record=0, use_connection_pool=0, g_connection_pool_max_idle_time=3600s[2018-01-20 12:37:18] INFO - file: storage_param_getter.c, line: 191, use_storage_id=0, id_type_in_filename=ip, storage_ip_changed_auto_adjust=1, store_path=0, reserved_storage_space=10.00%, use_trunk_file=0, slot_min_size=256, slot_max_size=16 MB, trunk_file_size=64 MB, trunk_create_file_advance=0, trunk_create_file_time_base=02:00, trunk_create_file_interval=86400, trunk_create_file_space_threshold=20 GB, trunk_init_check_occupying=0, trunk_init_reload_from_binlog=0, trunk_compress_binlog_min_interval=0, store_slave_file_use_link=0[2018-01-20 12:37:18] INFO - file: storage_func.c, line: 257, tracker_client_ip: 192.168.43.72, my_server_id_str: 192.168.43.72, g_server_id_in_filename: 1210820800[2018-01-20 12:37:18] INFO - file: tracker_client_thread.c, line: 310, successfully connect to tracker server 192.168.43.71:22122, as a tracker client, my ip is 192.168.43.72[2018-01-20 12:37:18] INFO - file: tracker_client_thread.c, line: 1947, tracker server: #0. 192.168.43.70:22122, my_report_status: -1[2018-01-20 12:37:18] INFO - file: tracker_client_thread.c, line: 310, successfully connect to tracker server 192.168.43.70:22122, as a tracker client, my ip is 192.168.43.72[2018-01-20 12:37:18] INFO - file: tracker_client_thread.c, line: 1947, tracker server: #0. 192.168.43.70:22122, my_report_status: -1[2018-01-20 12:37:48] INFO - file: tracker_client_thread.c, line: 1263, tracker server 192.168.43.71:22122, set tracker leader: 192.168.43.71:22122[2018-01-20 12:37:48] INFO - file: storage_sync.c, line: 2732, successfully connect to storage server 192.168.43.73:23000 发现此时192.168.43.71作为Tracker的Leader。 设置Storage开机自启动 1[root@localhost fdfs]# echo &quot;service fdfs_storaged start&quot; |tee -a /etc/rc.d/rc.local 安装fastdfs-nginx-module、Nginx模块 安装Nginx模块所需的依赖环境 123[root@localhost fdfs]# yum -y install pcre pcre-devel [root@localhost fdfs]# yum -y install zlib zlib-devel [root@localhost fdfs]# yum -y install openssl openssl-devel 解压nginx和fastdfs-nginx-module12[root@localhost fdfs]# tar -zxvf nginx-1.10.3.tar.gz[root@localhost fdfs]# unzip fastdfs-nginx-module-master.zip 进入Nginx解压目录进行编译安装1[root@localhost nginx-1.10.3]# ./configure --prefix=/usr/local/nginx --add-module=/home/zhangyongliang/apps/fastdfs-nginx-module-master/src #解压后fastdfs-nginx-module所在的位置 安装成功后，nginx会安装在/usr/local/nginx,安装后查看 123456789101112[root@localhost src]# ll /usr/local/nginx/总用量 8drwx------. 2 nobody root 6 1月 17 13:23 client_body_tempdrwxr-xr-x. 2 root root 4096 1月 17 13:17 confdrwx------. 2 nobody root 6 1月 17 13:23 fastcgi_tempdrwxr-xr-x. 2 root root 40 1月 17 13:17 htmldrwxr-xr-x. 2 root root 58 1月 17 13:49 logs-rw-r--r--. 1 root root 1156 1月 17 13:29 nginx.confdrwx------. 2 nobody root 6 1月 17 13:23 proxy_tempdrwxr-xr-x. 2 root root 19 1月 17 13:17 sbindrwx------. 2 nobody root 6 1月 17 13:23 scgi_tempdrwx------. 2 nobody root 6 1月 17 13:23 uwsgi_temp 安装成功后，nginx尚未运行时，nginx文件夹没有临时文件夹，例如fastcgi_temp这些文件。复制 fastdfs-nginx-module 源码中的配置文件到/etc/fdfs 目录， 并修改 12[root@localhost src]# cp /usr/local/src/fastdfs-nginx-module/src/mod_fastdfs.conf /etc/fdfs/ [root@localhost src]# vi /etc/fdfs/mod_fastdfs.conf 12345678910111213141516171819202122(1)第1组 Storage 的 mod_fastdfs.conf 配置如下： connect_timeout=10 base_path=/opt/fastdfs_storagetracker_server=192.168.1.131:22122 tracker_server=192.168.1.132:22122 storage_server_port=23000 group_name=group1 url_have_group_name = true store_path0=/opt/fastdfs_storage_datagroup_count = 2 [group1] group_name=group1 storage_server_port=23000 store_path_count=1 store_path0=/opt/fastdfs_storage_data[group2] group_name=group2 storage_server_port=23000 store_path_count=1 store_path0=/opt/fastdfs_storage_data (2)第2组 Storage 的 mod_fastdfs.conf 配置与第一组配置只有 group_name 不同： group_name=group2 完整信息如下：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136# connect timeout in seconds# default value is 30sconnect_timeout=2# network recv and send timeout in seconds# default value is 30snetwork_timeout=30# the base path to store log filesbase_path=/opt/fastdfs_storage# if load FastDFS parameters from tracker server# since V1.12# default value is falseload_fdfs_parameters_from_tracker=true# storage sync file max delay seconds# same as tracker.conf# valid only when load_fdfs_parameters_from_tracker is false# since V1.12# default value is 86400 seconds (one day)storage_sync_file_max_delay = 86400# if use storage ID instead of IP address# same as tracker.conf# valid only when load_fdfs_parameters_from_tracker is false# default value is false# since V1.13use_storage_id = false# specify storage ids filename, can use relative or absolute path# same as tracker.conf# valid only when load_fdfs_parameters_from_tracker is false# since V1.13storage_ids_filename = storage_ids.conf# FastDFS tracker_server can ocur more than once, and tracker_server format is# &quot;host:port&quot;, host can be hostname or ip address# valid only when load_fdfs_parameters_from_tracker is truetracker_server=192.168.43.70:22122tracker_server=192.168.43.71:22122# the port of the local storage server# the default value is 23000storage_server_port=23000# the group name of the local storage servergroup_name=group1# if the url / uri including the group name# set to false when uri like /M00/00/00/xxx# set to true when uri like $&#123;group_name&#125;/M00/00/00/xxx, such as group1/M00/xxx# default value is falseurl_have_group_name = true# path(disk or mount point) count, default value is 1# must same as storage.confstore_path_count=1# store_path#, based 0, if store_path0 not exists, it&apos;s value is base_path# the paths must be exist# must same as storage.confstore_path0=/opt/fastdfs_storage_data#store_path1=/home/yuqing/fastdfs1# standard log level as syslog, case insensitive, value list:### emerg for emergency### alert### crit for critical### error### warn for warning### notice### info### debuglog_level=info# set the log filename, such as /usr/local/apache2/logs/mod_fastdfs.log# empty for output to stderr (apache and nginx error_log file)log_filename=# response mode when the file not exist in the local file system## proxy: get the content from other storage server, then send to client## redirect: redirect to the original storage server (HTTP Header is Location)response_mode=proxy# the NIC alias prefix, such as eth in Linux, you can see it by ifconfig -a# multi aliases split by comma. empty value means auto set by OS type# this paramter used to get all ip address of the local host# default values is emptyif_alias_prefix=# use &quot;#include&quot; directive to include HTTP config file# NOTE: #include is an include directive, do NOT remove the # before include#include http.conf# if support flv# default value is false# since v1.15flv_support = true# flv file extension name# default value is flv# since v1.15flv_extension = flv# set the group count# set to none zero to support multi-group on this storage server# set to 0 for single group only# groups settings section as [group1], [group2], ..., [groupN]# default value is 0# since v1.14group_count = 2# group settings for group #1# since v1.14# when support multi-group on this storage server, uncomment following section[group1]group_name=group1storage_server_port=23000store_path_count=1store_path0=/opt/fastdfs_storage_data[group2]group_name=group2storage_server_port=23000store_path_count=1store_path0=/opt/fastdfs_storage_data# group settings for group #2# since v1.14# when support multi-group, uncomment following section as neccessary#[group2]#group_name=group2#storage_server_port=23000#store_path_count=1#store_path0=/home/yuqing/fastdfs 复制 FastDFS 安装目录的部分配置文件到/etc/fdfs 目录 123[root@localhost conf]# pwd/home/zhangyongliang/apps/fastdfs-5.11/conf[root@localhost conf]# cp http.conf mime.types /etc/fdfs/ 创建M00至storage存储目录的符号连接： 1ln -s /opt/fastdfs_storage_data/data/ /opt/fastdfs_storage_data/data/M00 配置 Nginx， 简洁版 nginx 配置样例 123456789101112131415161718192021222324# vi /usr/local/nginx/conf/nginx.conf user root; worker_processes 1; events &#123; worker_connections 1024; &#125; http &#123; include mime.types; default_type application/octet-stream; sendfile on; keepalive_timeout 65; server &#123; listen 8888; server_name localhost; location ~/group([0-9])/M00 &#123; #alias /fastdfs/storage/data; ngx_fastdfs_module; &#125; error_page 500 502 503 504 /50x.html; location = /50x.html &#123; root html; &#125; &#125; &#125; 注意、 说明： 8888 端口值是要与/etc/fdfs/storage.conf 中的 http.server_port=8888 相对应，因为 http.server_port 默认为 8888,如果想改成 80，则要对应修改过来。重新启动各节点的Nginx服务1[root@localhost conf]#/usr/local/nginx/sbin/nginx -s reload 4.文件上传测试执行节点Tracker01、Tracker02修改 Tracker 服务器中的客户端配置文件1234# vi /etc/fdfs/client.conf base_path=/fastdfs/tracker tracker_server=192.168.43.70:22122 tracker_server=192.168.43.71:22122 执行如下文件上传命令 1234[root@localhost zhangyongliang]# fdfs_upload_file /etc/fdfs/client.conf P71022-205803.jpg group1/M00/00/00/wKgrSFpjC26AH1g2AAvUQrxXbkA557.jpg[root@localhost zhangyongliang]# fdfs_upload_file /etc/fdfs/client.conf P71022-205803.jpg group2/M00/00/00/wKgrSlpjC3aAARrXAAvUQrxXbkA048.jpg 进行2次上传后，发现文件被均衡分到2个group。 5.Tracker安装Nginx、 ngx_cache_purge 模块 安装编译 Nginx 所需的依赖包1[root@localhost zhangyongliang]# yum install gcc gcc-c++ make automake autoconf libtool pcre pcre-devel zlib zlib-devel openssl openssl-devel 解压Nginx和ngx_cache_pure模块 12[root@localhost apps]# tar ngx_cache_purge-2.3.tar.gz[root@localhost apps]# tar nginx-1.10.3.tar.gz 编译安装 Nginx（添加 ngx_cache_purge 模块） 123[root@localhost apps]# cd nginx-1.13.0 [root@localhost nginx-1.13.0# ./configure --prefix=/usr/local/nginx --add-module=/usr/local/src/ngx_cache_purge-2.3 [root@localhost nginx-1.13.0]# make &amp;&amp; make install 配置 Nginx， 设置负载均衡以及缓存 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172# vi /usr/local/nginx/conf/nginx.conf #user nobody;worker_processes 1;#error_log logs/error.log;#error_log logs/error.log notice;#error_log logs/error.log info;#pid logs/nginx.pid;events &#123; worker_connections 1024;&#125;http &#123; include mime.types; default_type application/octet-stream; #log_format main &apos;$remote_addr - $remote_user [$time_local] &quot;$request&quot; &apos; # &apos;$status $body_bytes_sent &quot;$http_referer&quot; &apos; # &apos;&quot;$http_user_agent&quot; &quot;$http_x_forwarded_for&quot;&apos;; #access_log logs/access.log main; sendfile on; tcp_nopush on; #tcp_nopush on; #keepalive_timeout 0; keepalive_timeout 65; #gzip on; #设置缓存 server_names_hash_bucket_size 128; client_header_buffer_size 32k; large_client_header_buffers 4 32k; client_max_body_size 300m; proxy_redirect off; proxy_set_header Host $http_host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_connect_timeout 90; proxy_send_timeout 90; proxy_read_timeout 90; proxy_buffer_size 16k; proxy_buffers 4 64k; proxy_busy_buffers_size 128k; proxy_temp_file_write_size 128k; #设置缓存存储路径，存储方式，分别内存大小，磁盘最大空间，缓存期限 proxy_cache_path /opt/fastdfs_tracker/proxy_cache levels=1:2 keys_zone=http-cache:200m max_size=1g inactive=30d; proxy_temp_path /opt/fastdfs_tracker/tmp; #group1的服务设置 upstream fdfs_group1 &#123; server 192.168.43.72:8888 weight=1 max_fails=2 fail_timeout=30s; server 192.168.43.73:8888 weight=1 max_fails=2 fail_timeout=30s; &#125; #group2的服务设置 upstream fdfs_group2 &#123; server 192.168.43.74:8888 weight=1 max_fails=2 fail_timeout=30s; server 192.168.43.75:8888 weight=1 max_fails=2 fail_timeout=30s; &#125; server &#123; listen 8000; server_name localhost; #charset koi8-r; #access_log logs/host.access.log main; #group1的负载均衡配置 location /group1/M00 &#123; proxy_next_upstream http_502 http_504 error timeout invalid_header; proxy_cache http-cache; proxy_cache_valid 200 304 12h; proxy_cache_key $uri$is_args$args; #对应group1的服务设置 proxy_pass http://fdfs_group1; expires 30d; &#125; location /group2/M00 &#123; proxy_next_upstream http_502 http_504 error timeout invalid_header; proxy_cache http-cache; proxy_cache_valid 200 304 12h; proxy_cache_key $uri$is_args$args; #对应group2的服务设置 proxy_pass http://fdfs_group2; expires 30d; &#125; location ~/purge(/.*) &#123; allow 127.0.0.1; allow 192.168.43.0/24; deny all; proxy_cache_purge http-cache $1$is_args$args; &#125; location / &#123; root html; index index.html index.htm; &#125; #error_page 404 /404.html; # redirect server error pages to the static page /50x.html # error_page 500 502 503 504 /50x.html; location = /50x.html &#123; root html; &#125; # proxy the PHP scripts to Apache listening on 127.0.0.1:80 # #location ~ \\.php$ &#123; # proxy_pass http://127.0.0.1; #&#125; # pass the PHP scripts to FastCGI server listening on 127.0.0.1:9000 # #location ~ \\.php$ &#123; # root html; # fastcgi_pass 127.0.0.1:9000; # fastcgi_index index.php; # fastcgi_param SCRIPT_FILENAME /scripts$fastcgi_script_name; # include fastcgi_params; #&#125; # deny access to .htaccess files, if Apache&apos;s document root # concurs with nginx&apos;s one # #location ~ /\\.ht &#123; # deny all; #&#125; &#125; # another virtual host using mix of IP-, name-, and port-based configuration # #server &#123; # listen 8000; # listen somename:8080; # server_name somename alias another.alias; # location / &#123; # root html; # index index.html index.htm; # &#125; #&#125; # HTTPS server # #server &#123; # listen 443 ssl; # server_name localhost; # ssl_certificate cert.pem; # ssl_certificate_key cert.key; # ssl_session_cache shared:SSL:1m; # ssl_session_timeout 5m; # ssl_ciphers HIGH:!aNULL:!MD5; # ssl_prefer_server_ciphers on; # location / &#123; # root html; # index index.html index.htm; # &#125; #&#125;&#125; 根据Nginx配置，创建对应目录下的文件夹 1234567[root@localhost fastdfs_tracker]# mkdir proxy_cache tmp[root@localhost fastdfs_tracker]# ll总用量 0drwxr-xr-x. 2 root root 178 1月 20 12:37 datadrwxr-xr-x. 2 root root 26 1月 19 12:01 logsdrwxr-xr-x. 7 nobody root 51 1月 19 19:35 proxy_cachedrwxr-xr-x. 2 nobody root 6 1月 19 19:35 tmp 重启Nginx进行访问测试 12重启 Nginx [root@localhost fastdfs_tracker]# /usr/local/nginx/sbin/nginx -s reload 前面直接通过访问 Storage 节点中的 Nginx 的文件http://192.168.43.72:8888/group1/M00/00/00/wKgrSFpjC26AH1g2AAvUQrxXbkA557.jpg]http://192.168.43.74:8888/group2/M00/00/00/wKgrSlpjC3aAARrXAAvUQrxXbkA048.jpg现在可以通过 Tracker 中的 Nginx 来进行访问(1)通过 Tracker1 中的 Nginx 来访问http://192.168.43.70:8000/group1/M00/00/00/wKgrSFpjC26AH1g2AAvUQrxXbkA557.jpghttp://192.168.43.70:8000/group2/M00/00/00/wKgrSlpjC3aAARrXAAvUQrxXbkA048.jpg(2)通过 Tracker2 中的 Nginx 来访问http://192.168.43.71:8000/group1/M00/00/00/wKgrSFpjC26AH1g2AAvUQrxXbkA557.jpghttp://192.168.50.71:8000/group2/M00/00/00/wKgrSlpjC3aAARrXAAvUQrxXbkA048.jpg 6.构建Keepalive+Nginx 实现虚拟IP的代理关于使用Keepalive+Nginx进行代理的环境安装，请参考本人简书此文：Keepalived+Nginx+Tomcat 实现高可用Web集群 本文不再做赘述说明 启动Keepalvie+nginx Master主节点【192.168.43.101】 启动Keepalvie+nginx BackUp备节点【192.168.43.102】修改2个节点Nginx下目录的nginx.conf的配置文件信息，添加如下内容主要内容为2个Tracker加入到Keepalive+nginx代理当中1234upstream fastdfs_tracker &#123; server 192.168.43.70:8000 weight=1 max_fails=2 fail_timeout=30s; server 192.168.43.71:8000 weight=1 max_fails=2 fail_timeout=30s; &#125; 第二处修改是添加了一个location并且匹配规则是路径当中有fastdfs 1234567891011location /fastdfs &#123; root html; index index.html index.htm; proxy_pass http://fastdfs_tracker/; proxy_set_header Host $http_host; proxy_set_header Cookie $http_cookie; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_set_header X-Forwarded-Proto $scheme; client_max_body_size 300m; &#125; 完整配置代码如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138#user nobody;worker_processes 1;#error_log logs/error.log;#error_log logs/error.log notice;#error_log logs/error.log info;#pid logs/nginx.pid;events &#123; worker_connections 1024;&#125;http &#123; include mime.types; default_type application/octet-stream; #log_format main &apos;$remote_addr - $remote_user [$time_local] &quot;$request&quot; &apos; # &apos;$status $body_bytes_sent &quot;$http_referer&quot; &apos; # &apos;&quot;$http_user_agent&quot; &quot;$http_x_forwarded_for&quot;&apos;; #access_log logs/access.log main; sendfile on; #tcp_nopush on; #keepalive_timeout 0; keepalive_timeout 65; #gzip on; upstream fastdfs_tracker &#123; server 192.168.43.70:8000 weight=1 max_fails=2 fail_timeout=30s; server 192.168.43.71:8000 weight=1 max_fails=2 fail_timeout=30s; &#125; upstream tomcat&#123; server 192.168.43.103:8080 weight=1; server 192.168.43.104:8080 weight=1; &#125; server &#123; listen 80; server_name localhost; #charset koi8-r; #access_log logs/host.access.log main; location / &#123; proxy_pass http://tomcat; proxy_set_header X-NGINX &quot;NGINX-1&quot;; root html; index index.html index.htm; &#125; #error_page 404 /404.html; # redirect server error pages to the static page /50x.html # error_page 500 502 503 504 /50x.html; location = /50x.html &#123; root html; &#125; location /fastdfs &#123; root html; index index.html index.htm; proxy_pass http://fastdfs_tracker/; proxy_set_header Host $http_host; proxy_set_header Cookie $http_cookie; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_set_header X-Forwarded-Proto $scheme; client_max_body_size 300m; &#125; # proxy the PHP scripts to Apache listening on 127.0.0.1:80 # #location ~ \\.php$ &#123; # proxy_pass http://127.0.0.1; #&#125; # pass the PHP scripts to FastCGI server listening on 127.0.0.1:9000 # #location ~ \\.php$ &#123; # root html; # fastcgi_pass 127.0.0.1:9000; # fastcgi_index index.php; # fastcgi_param SCRIPT_FILENAME /scripts$fastcgi_script_name; # include fastcgi_params; #&#125; # deny access to .htaccess files, if Apache&apos;s document root # concurs with nginx&apos;s one # #location ~ /\\.ht &#123; # deny all; #&#125; &#125; # another virtual host using mix of IP-, name-, and port-based configuration # #server &#123; # listen 8000; # listen somename:8080; # server_name somename alias another.alias; # location / &#123; # root html; # index index.html index.htm; # &#125; #&#125; # HTTPS server # #server &#123; # listen 443 ssl; # server_name localhost; # ssl_certificate cert.pem; # ssl_certificate_key cert.key; # ssl_session_cache shared:SSL:1m; # ssl_session_timeout 5m; # ssl_ciphers HIGH:!aNULL:!MD5; # ssl_prefer_server_ciphers on; # location / &#123; # root html; # index index.html index.htm; # &#125; #&#125;&#125; 修改之后，重新启动Keepalive+Nginx2台主备节点。 1[root@nginx1 conf]# /usr/local/nginx/sbin/nginx -s reload 我们现在就用虚拟IP192.168.43.150来访问我们刚才上传的图片，只是注意在地址栏中要记得输入fastdfs（这是我们nginx.conf文件中location /fastdfs{}规则规定的）。如下图所示，发现，我们通过虚拟IP便可以访问我们上传的图片了。这样的好处是，对用户来说，只需要访问这个虚拟IP就可以了，不用关心FastDFS集群内部的转发机制。 集群VIP访问截图.png 至此，分布式文件系统就搭建完成了，在通过Java访问时，只要在配置文件配置所有的Tracker节点IP信息就可以啦！ 补充说明：如果Tracker 服务、Storage服务、Nginx服务开机后没有自启动，请执行一下操作并进行重启 12[root@localhost ~]# chkconfig --add fdfs_trackerd[root@localhost ~]# chkconfig --add fdfs_storaged 编辑目录下的/etc/rc.d/rc.local,内容如下：1234567891011121314#!/bin/bash# THIS FILE IS ADDED FOR COMPATIBILITY PURPOSES## It is highly advisable to create own systemd services or udev rules# to run scripts during boot instead of using this file.## In contrast to previous versions due to parallel execution during boot# this script will NOT be run after all other services.## Please note that you must run &apos;chmod +x /etc/rc.d/rc.local&apos; to ensure# that this script will be executed during boot.touch /var/lock/subsys/local/usr/local/nginx/sbin/nginx 主要增加了Nginx的启动，之后进行文件生效，重新启动系统 123[root@localhost ~]# chmod +x /etc/rc.d/rc.local[root@localhost ~]# source /etc/rc.d/rc.local [root@localhost ~]# reboot","tags":[]},{"title":"Hive高级操作","date":"2018-02-01T05:51:58.981Z","path":"2018/02/01/Hive高级查询操作/","text":"Hive高级操作1.使用LIKE、AS创建表,表重命名，添加、修改、删除列 表结构数据复制根据已存在的表结构，使用like关键字，复制一个表结构一模一样的新表 123456789101112hive&gt; create table student_info2 like student_info;OKTime taken: 0.73 secondshive&gt; show tables;OKemployeestudent_infostudent_info2student_school_infostudent_school_info_external_partitionstudent_school_info_partitionTime taken: 0.15 seconds, Fetched: 6 row(s) 根据已经存在的表，使用as关键字，创建一个与查询结果字段一致的表，同时将查询结果数据插入到新表 1create table student_info3 as select * from student_info; 只有student_id,name两个字段的表 1create table student_info4 as select student_id,name from student_info; 表重命名student_info4表重命名为student_id_name 1alter table student_info4 rename to student_id_name; 添加列给student_info3表添加性别列,新添加的字段会在所有列最后，分区列之前，在添加新列之前已经存在的数据文件中。如果没有新添加列对应的数据，在查询的时候显示为空。添加多个列用逗号隔开。 123hive&gt; alter table student_info3 add columns(gender string comment &apos;性别&apos;);OKTime taken: 0.185 seconds 删除列或修改列修改列，将继续存在的列再定义一遍，需要替换的列重新定义 123hive&gt; alter table student_info3 replace columns(student_id string,name string,age int,origin string,gender2 int);OKTime taken: 0.422 seconds 删除列,将继续存在的列再定义一遍，需要删除的列不再定义 123hive&gt; alter table student_info3 replace columns(student_id string,name string,age int,origin string);OKTime taken: 0.529 seconds 2.分桶表使用 创建分桶表按照指定字段取它的hash散列值分桶,创建学生入学信息分桶表 字段名称 类型 注释 分桶字段 student_id string 学生ID 是 name string 姓名 否 age int 年龄 否 origin string 学院ID 否 1234567891011create table rel.student_info_bucket(student_id string,name string,age int,origin string)clustered by (student_id) sorted by (student_id asc) into 4 buckets row format delimited fields terminated by &apos;\\t&apos; lines terminated by &apos;\\n&apos; stored as textfile; 分桶表插入数据向student_info_bucket分桶表插入数据 123456set hive.enforce.bucketing = true;set mapreduce.job.reduces=4;insert overwrite table student_info_bucket select student_id,name,age,origin from student_info cluster by(student_id); 查看hdfs分桶文件 123456[root@hadoop01 ~]# hadoop fs -ls /user/hive/warehouse/rel.db/student_info_bucketFound 4 items-rwxr-xr-x 3 hadoop supergroup 78 2018-01-24 19:33 /user/hive/warehouse/rel.db/student_info_bucket/000000_0-rwxr-xr-x 3 hadoop supergroup 84 2018-01-24 19:33 /user/hive/warehouse/rel.db/student_info_bucket/000001_0-rwxr-xr-x 3 hadoop supergroup 80 2018-01-24 19:33 /user/hive/warehouse/rel.db/student_info_bucket/000002_0-rwxr-xr-x 3 hadoop supergroup 81 2018-01-24 19:33 /user/hive/warehouse/rel.db/student_info_bucket/000003_0 说明： 分桶表一般不使用load向分桶表中导入数据，因为load导入数据只是将数据复制到表的数据存储目录下，hive并不会在load的时候对数据进行分析然后按照分桶字段分桶，load只会将一个文件全部导入到分桶表中，并没有分桶。一般采用insert从其他表向分桶表插入数据。分桶表在创建表的时候只是定义表的模型，插入的时候需要做如下操作：在每次执行分桶插入的时候在当前执行的session会话中要设置 1hive.enforce.bucketing=true; 声明本次执行的是一次分桶操作。需要指定reduce个数与分桶的数量相同 1set mapreduce.job.reduces=4， 这样才能保证有多少桶就生成多少个文件。如果定义了按照分桶字段排序，需要在从其他表查询数据过程中将数据按照分区字段排序之后插入各个桶中，分桶表并不会将各分桶中的数据排序。排序和分桶的字段相同的时候使用Cluster by(字段),cluster by 默认按照分桶字段在桶内升序排列，如果需要在桶内降序排列，使用distribute by (col) sort by (col desc)组合实现。 3.导出数据 使用insert将student_info表数据导出到本地指定路径 12insert overwrite local directory &apos;/home/hadoop/apps/hive_test_data/export_data&apos; row format delimited fields terminated by &apos;\\t&apos; select * from student_info; 123456789101112131415161718192021[root@hadoop01 export_data]# cat 000000_0 1 xiaoming 20 112 xiaobai 21 313 zhangfei 22 444 likui 19 445 zhaoyun 21 136 zhangsan 20 117 lisi 19 118 wangwu 23 319 zhaofei 19 2110 zhangyan 20 2111 lihe 20 2212 caoyang 17 3213 lihao 19 3214 zhaoming 21 5015 zhouhong 18 5116 yangshuo 23 3317 xiaofei 24 1318 liman 23 1319 qianbao 20 1320 sunce 21 41 导出数据到本地的常用方法1[hadoop@hadoop01 export_data]$ hive -e&quot;select * from rel.student_info&quot;&gt; /home/hadoop/student_info_data.txt 123456789101112131415161718192021[hadoop@hadoop01 ~]$ cat student_info_data.txt 1 xiaoming 20 112 xiaobai 21 313 zhangfei 22 444 likui 19 445 zhaoyun 21 136 zhangsan 20 117 lisi 19 118 wangwu 23 319 zhaofei 19 2110 zhangyan 20 2111 lihe 20 2212 caoyang 17 3213 lihao 19 3214 zhaoming 21 5015 zhouhong 18 5116 yangshuo 23 3317 xiaofei 24 1318 liman 23 1319 qianbao 20 1320 sunce 21 41 默认结果分隔符：’\\t’ 4.关联查询 创建2张表 1234567891011121314151617create table rel.a(id int,name string)row format delimited fields terminated by &apos;\\t&apos; lines terminated by &apos;\\n&apos; stored as textfile;create table rel.b(id int,name string)row format delimited fields terminated by &apos;\\t&apos; lines terminated by &apos;\\n&apos; stored as textfile; 导入数据 12345678910hive&gt; load data local inpath &apos;/home/hadoop/apps/hive_test_data/a_join_data&apos; into table a;Loading data to table rel.aTable rel.a stats: [numFiles=1, totalSize=61]OKTime taken: 1.79 secondshive&gt; load data local inpath &apos;/home/hadoop/apps/hive_test_data/b_join_data&apos; into table b;Loading data to table rel.bTable rel.b stats: [numFiles=1, totalSize=38]OKTime taken: 0.562 seconds inner或inner join两个表通过id关联，只把id值相等的数据查询出来。join的查询结果与inner join的查询结果相同。 1select * from a join b on a.id=b.id; 等同于 12345678select * from a inner join b on a.id=b.id;.....OK1 a 1 AA2 b 2 BB3 c 3 CC6 f 6 FFTime taken: 44.337 seconds, Fetched: 4 row(s) full outer join或full join 两个表通过id关联，把两个表的数据全部查询出来123456789101112131415161718OK1 a 1 AA2 b 2 BB3 c 3 CC4 d NULL NULL5 e NULL NULL6 f 6 FF7 g NULL NULL8 h NULL NULL9 i NULL NULL10 j NULL NULL11 k NULL NULL12 l NULL NULL13 m NULL NULL14 n NULL NULLNULL NULL 20 TTNULL NULL 21 UUNULL NULL 22 vv left join 左连接时，左表中出现的join字段都保留，右表没有连接上的都为空 123456789101112131415OK1 a 1 AA2 b 2 BB3 c 3 CC4 d NULL NULL5 e NULL NULL6 f 6 FF7 g NULL NULL8 h NULL NULL9 i NULL NULL10 j NULL NULL11 k NULL NULL12 l NULL NULL13 m NULL NULL14 n NULL NULL right join 右连接时，右表中出现的join字段都保留，左表没有连接上的都是空 1select * from a right join b on a.id=b.id; 123456789OK1 a 1 AA2 b 2 BB3 c 3 CC6 f 6 FFNULL NULL 20 TTNULL NULL 21 UUNULL NULL 22 vvTime taken: 25.188 seconds, Fetched: 7 row(s) left semi join 左半连接实现了类似IN/EXISTS的查询语义，输出符合条件的左表内容。hive不支持in …exists这种关系型数据库中的子查询结构，hive暂时不支持右半连接。例如： 1select a.id, a.name from a where a.id in (select b.id from b); 使用Hive对应于如下语句： 1select a.id,a.name from a left semi join b on a.id = b.id; 123456OK1 a2 b3 c6 fTime taken: 27.42 seconds, Fetched: 4 row(s) map side join 使用分布式缓存将小表数据加载都各个map任务中，在map端完成join，map任务输出后，不需要将数据拷贝到reducer阶段再进行join，降低的数据在网络节点之间传输的开销。多表关联数据倾斜优化的一种手段。多表连接，如果只有一个表比较大，其他表都很小，则join操作会转换成一个只包含map的Job。运行日志中会出现Number of reduce tasks is set to 0 since there’s no reduce operator没有reduce的提示。例如： 1select /*+ mapjoin(b) */ a.id, a.name from a join b on a.id = b.id 1234567Total MapReduce CPU Time Spent: 1 seconds 320 msecOK1 a2 b3 c6 fTime taken: 25.538 seconds, Fetched: 4 row(s) 5.Hive内置函数创建用户评分表 123456789create table rel.user_core_info(user_id string,age int,gender string,core int)row format delimited fields terminated by &apos;\\t&apos; lines terminated by &apos;\\n&apos;stored as textfile; 导入数据 1load data local inpath &apos;/home/hadoop/apps/hive_test_data/user_core.txt&apos; into table rel.user_core_info; 条件函数 case when 语法1：CASE a WHEN b THEN c [WHEN d THEN e]* [ELSE f] END 说明：如果a等于b，那么返回c；如果a等于d，那么返回e；否则返回f例如： 1234hive&gt; select case 1 when 2 then &apos;two&apos; when 1 then &apos;one&apos; else &apos;zero&apos; end;OKoneTime taken: 0.152 seconds, Fetched: 1 row(s) 语法2：CASE WHEN a THEN b [WHEN c THEN d]* [ELSE e] END说明：如果a为TRUE，则返回b；如果c为TRUE，则返回d；否则返回e例如： 1234hive&gt; select case when 1=2 then &apos;two&apos; when 1=1 then &apos;one&apos; else &apos;zero&apos; end;OKoneTime taken: 0.33 seconds, Fetched: 1 row(s) 查询用户评分表，每个年龄段的最大评分值 123456select gender,case when age&lt;=20 then &apos;p0&apos; when age&gt;20 and age&lt;=50 then &apos;p1&apos; when age&gt;=50 then &apos;p3&apos; else &apos;p0&apos; end,max(core) max_corefrom rel.user_core_info group by gender,case when age&lt;=20 then &apos;p0&apos; when age&gt;20 and age&lt;=50 then &apos;p1&apos; when age&gt;=50 then &apos;p3&apos; else &apos;p0&apos; end; 结果为： 12345678OKfemale p0 90female p1 95female p3 90male p0 80male p1 80male p3 80Time taken: 28.461 seconds, Fetched: 6 row(s) 自定义UDF函数 当Hive提供的内置函数无法满足你的业务处理需要时，此时就可以考虑使用用户自定义函数（UDF：user-defined function）。UDF 作用于单个数据行，产生一个数据行作为输出。步骤： 先开发一个java类，继承UDF，并重载evaluate方法 打成jar包上传到服务器 在使用的时候将jar包添加到hive的classpath 1hive&gt;add jar /home/hadoop/apps/hive_test_data/HiveUdfPro-1.0-SNAPSHOT.jar; 创建临时函数与开发好的java class关联 1hive&gt;create temporary function age_partition as &apos;cn.chinahadoop.udf.AgePartitionFunction&apos;; 即可在hql中使用自定义的函数新建Maven 项目Pom 信息如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;com.yongliang.udf&lt;/groupId&gt; &lt;artifactId&gt;HiveUdfPro&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;packaging&gt;jar&lt;/packaging&gt; &lt;name&gt;HiveUdfPro&lt;/name&gt; &lt;url&gt;http://maven.apache.org&lt;/url&gt; &lt;properties&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt; &lt;/properties&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.hive&lt;/groupId&gt; &lt;artifactId&gt;hive-exec&lt;/artifactId&gt; &lt;version&gt;1.2.2&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.hadoop&lt;/groupId&gt; &lt;artifactId&gt;hadoop-common&lt;/artifactId&gt; &lt;version&gt;2.7.0&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-compiler-plugin&lt;/artifactId&gt; &lt;version&gt;2.3.2&lt;/version&gt; &lt;executions&gt; &lt;execution&gt; &lt;id&gt;default-compile&lt;/id&gt; &lt;phase&gt;compile&lt;/phase&gt; &lt;goals&gt; &lt;goal&gt;compile&lt;/goal&gt; &lt;/goals&gt; &lt;configuration&gt; &lt;encoding&gt;UTF-8&lt;/encoding&gt; &lt;/configuration&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt;&lt;/project&gt; 新建类继承UDF 123456789101112131415161718192021package com.yongliang.udf;import org.apache.hadoop.hive.ql.exec.UDF;/** * 创建时间 : 2018/1/27 15:35 * 类描述 : Hive UDF自定义函数，作用于单个数据行，产生一个数据行作为输出 * @author zhangyonglaing */public class AgePartitionFunction extends UDF &#123; public String evaluate(int age) &#123; String partition = &quot;p0&quot;; if(age &lt;=20)&#123; partition = &quot;p0&quot;; &#125;else if(age &gt; 20 &amp;&amp; age &lt;=50)&#123; partition = &quot;p1&quot;; &#125;else if(age &gt; 50)&#123; partition = &quot;p2&quot;; &#125; return partition; &#125;&#125; 将项目进行打包 Hive UDF 自定义函数 说明: 如出现以下异常信息：Failed to execute goal on project hive-exec:Could not resolve dependencies for project org.apache.hive:hive-exec:jar:2.3.0:Could not find artifact org.pentaho:pentaho-aggdesigner-algorithm:jar:5.1.5-jhyde in alimaven (http://maven.aliyun.com/nexus/content/groups/public/) -&gt; [Help 1] 错误异常信息 请手动下载Jar包pentaho-aggdesigner-algorithm/5.1.5-jhyde.jar 下载地址：https://public.nexus.pentaho.org/content/groups/omni/org/pentaho/pentaho-aggdesigner-algorithm/5.1.5-jhyde/ 将Jar包放置在本地Maven仓库org/pentaho/pentaho-aggdesigner-algorithm/5.1.5-jhyde路径下，之后进行重新打包。 将jar包添加到hive的classpath 123hive&gt; add jar /home/hadoop/apps/HiveUdfPro-1.0-SNAPSHOT.jar;Added [/home/hadoop/apps/HiveUdfPro-1.0-SNAPSHOT.jar] to class pathAdded resources: [/home/hadoop/apps/HiveUdfPro-1.0-SNAPSHOT.jar] 创建临时函数与开发好的java class关联 1hive&gt; create temporary function age_partition as &apos;com.yongliang.udf.AgePartitionFunction&apos;; 在hql中使用自定义的函数 123456select gender,age_partition(age),max(core) max_corefrom rel.user_core_info group by gender,age_partition(age); 结果为：1234567OKfemale p0 90female p1 95female p2 90male p0 80male p1 80male p2 80","tags":[]},{"title":"Hello World","date":"2018-01-30T14:51:46.487Z","path":"2018/01/30/hello-world/","text":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new \"My New Post\" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment","tags":[]}]